{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delay Report\n",
    "### Overview\n",
    "The delay report script aims to find the updated_eta and updated_etd of certain vessels provided within \"Vessel Delay Tracking.XLSX\". This is done by querying an underlying BigSchedules API, MSC Web API and from a static G2 Schedules Excel document. None of the API interactions use the Rio Tinto credentials to ensure that traceback cannot occur.\n",
    "\n",
    "The script is written in a modular approach to increase ease of maintenance and improve code quality. Configurations are stored in a `data` subdirectory. The script expects a `Vessel Delay Tracking.XLSX` file and `g2_filename` (G2 Schedule Excel file) in the same directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import logging\n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "import time\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from pathlib import Path\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "# pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read configuration file\n",
    "with open(\"data/config.json\", \"r\") as f:\n",
    "    config = json.load(f)\n",
    "    \n",
    "# Used to map carrier names to the ones BigSchedule uses and supports\n",
    "with open(\"data/carrier_mapping.json\", \"r\") as f:\n",
    "    carrier_mapping = json.load(f)\n",
    "\n",
    "# Bigschedule login\n",
    "with open(\"data/bigschedules_login.json\", \"r\") as f:\n",
    "    bs_login = json.load(f)\n",
    "    \n",
    "# Prepare base information\n",
    "# UNLOCODE to port name mapping\n",
    "port_mapping = (\n",
    "    pd.concat([pd.read_csv(p, usecols=[1, 2, 4, 5], engine='python', names=[\n",
    "              'country', 'port', 'name', 'subdiv']) for p in Path('data').glob(\"*UNLOCODE CodeListPart*\")])\n",
    "    .query('port == port')\n",
    "    .assign(\n",
    "        uncode=lambda x: x.country.str.cat(x.port),\n",
    "        full_name=lambda x: np.where(\n",
    "            x.subdiv.notnull(), x.name.str.cat(x.subdiv, sep=\", \"), x.name)\n",
    "    )\n",
    "    .drop_duplicates('uncode')\n",
    "    .set_index('uncode')\n",
    "    .to_dict('index')\n",
    ")\n",
    "\n",
    "# Read the vessel delay tracking file\n",
    "xl = pd.ExcelFile('Vessel Delay Tracking.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BSExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigschedules_sheet = (\n",
    "    xl.parse(pd.to_datetime(xl.sheet_names,\n",
    "                            errors='coerce',\n",
    "                            format='%d.%m.%Y').max().date().strftime('%d.%m.%Y'),\n",
    "                            parse_dates=True)\n",
    "                            .query(f\"`Fwd Agent` in {[k for k,v in carrier_mapping.items() if v != '']}\")\n",
    "                            .replace({'Fwd Agent': carrier_mapping})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get port name\n",
    "bigschedules_sheet = bigschedules_sheet.assign(\n",
    "    pol_name=lambda x: x['Port of Loading'].apply(\n",
    "        lambda y: port_mapping.get(y)['name']),\n",
    "    pod_name=lambda x: x['Port of discharge'].apply(\n",
    "        lambda y: port_mapping.get(y)['name']),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine what searches need to be made (splitting of concerns amongst BigSchedules, MSC & G2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the searches on the BigSchedules portal\n",
    "'''\n",
    "Takes in a list of dataframe of vessels, their carriers, POL, POD.\n",
    "Shrinks the above dataframe to vessels & their carriers. Uses this new dataframe for querying BigSchedules.\n",
    "Outputs an updated dataframe of vessels & their carriers with 2 additional columns updated_eta and updated_etd.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSCExtractor\n",
    "Currently, there are 2 main Web APIs which we can use for data extraction. These are:\n",
    "1. MSC Search Schedules API\n",
    "    - countryID API\n",
    "2. MSC Arrival-Departure API\n",
    "\n",
    "The Search Schedules API is forward looking and is the preferred mode of extraction. We will extract information for all lines for this first. If the information extraction fails, we will than treat the line as having a vessel that has already left port. We then use the Arrival-Departure API to extract the information for these.\n",
    "\n",
    "The countryID API is a sub-API used jointly with the Search Schedules API, which we will need to query before using the Search Schedules API because the parameters for the Search Schedules API uses numbers instead of the UNLOCODEs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To-do\n",
    "1. Now I just need to figure out how to get the first cookie and use it in subsequent headers.\n",
    "2. Add some randomness to the API call interval to reduce chances of being blocked.\n",
    "3. Can get ETA and ETD separately using POL-Vessel-Voyage and POD-Vessel-Voyage as keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the MSC delay sheet\n",
    "msc_delay_sheet = (xl.parse(pd.to_datetime(xl.sheet_names,\n",
    "                            errors='coerce',\n",
    "                            format='%d.%m.%Y').max().date().strftime('%d.%m.%Y'),\n",
    "                            parse_dates=True)\n",
    "                            .query(f\"`Fwd Agent` in {['MSC']}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the MSC-specific port names from the UNLOCODEs\n",
    "msc_port_mapping = {v['Port Code']: v['MSC Port Name'] for k,v in (pd.read_excel('data/MSC Port Code Mapping.xlsx')\n",
    "                                                                   .to_dict('index').items())}\n",
    "\n",
    "# Get port name\n",
    "msc_delay_sheet = msc_delay_sheet.assign(pol_name=lambda x: x['Port of Loading'].apply(lambda y: msc_port_mapping.get(y)),\n",
    "                                         pod_name=lambda x: x['Port of discharge'].apply(lambda y: msc_port_mapping.get(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = requests.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSC countryID API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_id(port):\n",
    "    url = f\"https://www.msc.com/api/schedules/autocomplete?q={port}\"\n",
    "    return session.request(\"GET\", url)\n",
    "\n",
    "def get_id(response):\n",
    "    if len(response.json()):\n",
    "        return response.json()[0].get('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msc_locations = list(msc_delay_sheet.pol_name.unique()) + list(msc_delay_sheet.pod_name.unique())\n",
    "responses = {location: query_id(location) for location in tqdm(msc_locations)}\n",
    "msc_port_id = {k:get_id(v) for k,v in responses.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PODs with no pod_id\n",
    "[k for k,v in msc_port_id.items() if v is None]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSC Search Schedules API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataframes:\n",
    "1. msc_delay_sheet: Ultimately the one we want to fill up\n",
    "2. reduced_df: The list of port pairs we need to request from MSC (no need ETD date because all vessels are this month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Further filter by POL-Vessel-Voyage to get ETD, POD-Vessel-Voyage to get ETA\n",
    "key = ['pol_name', 'pod_name']\n",
    "reduced_df = msc_delay_sheet.drop_duplicates(key)[key].sort_values(key)\n",
    "\n",
    "reduced_df['pol_code'] = reduced_df.pol_name.map(msc_port_id)\n",
    "reduced_df['pod_code'] = reduced_df.pod_name.map(msc_port_id)\n",
    "\n",
    "# Unable to handle those with no pod_id in MSC; dropping these lines\n",
    "reduced_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_schedules(etd, pol, pod):\n",
    "    url = f\"https://www.msc.com/api/schedules/search?WeeksOut=8&DirectRoutes=false&Date={etd}&From={pol}&To={pod}\"\n",
    "    headers = {\n",
    "        'Accept': 'application/json',\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/84.0.4147.105 Safari/537.36',\n",
    "        'Content-Type': 'application/json',\n",
    "        'Sec-Fetch-Site': 'same-origin',\n",
    "        'Sec-Fetch-Mode': 'cors',\n",
    "        'Sec-Fetch-Dest': 'empty',\n",
    "        'Referer': 'https://www.msc.com/search-schedules',\n",
    "        'Accept-Language': 'en-GB,en;q=0.9',\n",
    "        'Cookie': 'CMSPreferredCulture=en-GB; ASP.NET_SessionId=tht5lkut0asln2goiskoagfe; UrlReferrer=https://www.google.com/; CurrentContact=8b0b2fea-705b-4a4f-b8bf-bb1cd6c982bc; MSCAgencyId=115867; BIGipServerkentico.app~kentico_pool=439883018.20480.0000; _ga=GA1.2.1736073830.1597290148; _gid=GA1.2.1289141279.1597290148; _gcl_au=1.1.345060449.1597290148; __hstc=100935006.13bb76c8a78a8d0a203a993ffef3a3f6.1597290148282.1597290148282.1597290148282.1; hubspotutk=13bb76c8a78a8d0a203a993ffef3a3f6; __hssrc=1; _ym_uid=15972901491036911544; _ym_d=1597290149; _ym_isad=1; newsletter-signup-cookie=temp-hidden; _hjid=3e183004-f562-4048-8b60-daccdf9c187c; _hjUserAttributesHash=2c3b62a0e1cd48bdfd4d01b922060e19; _hjCachedUserAttributes={\"attributes\":{\"mscAgencyId\":\"115867\"},\"userId\":null}; OptanonAlertBoxClosed=2020-08-13T03:42:45.080Z; CMSCookieLevel=200; VisitorStatus=11062214903; TS0142aef9=0192b4b6225179b1baa3b4d270b71a4eee782a0192338173beabaa471f306c2a13fe854bf6a7ac08ac21924991864aa7728c54559023beabd273d82285d5f943202adb58da417d61813232e89b240828c090f890c6a74dc4adfec38513d13447be4b5b4404d69f964987b7917f731b858f0c9880a139994b98397c4aeb5bd60b0d0e38ec9e5f3c97b13fb184b4e068506e6086954f8a515f2b7239d2e5c1b9c70f61ca74f736355c58648a6036e9b5d06412389ac41221c5cb740df99c84dc2bfef4a530dbc5e2577c189212eebac723d9ee9f98030f4bc6ca7d824ab313ae5fdd1eaa9886; OptanonConsent=isIABGlobal=false&datestamp=Thu+Aug+13+2020+11%3A43%3A36+GMT%2B0800+(Singapore+Standard+Time)&version=5.9.0&landingPath=NotLandingPage&groups=1%3A1%2C2%3A1%2C3%3A1%2C4%3A1%2C0_53017%3A1%2C0_53020%3A1%2C0_53018%3A1%2C0_53019%3A1%2C101%3A1&AwaitingReconsent=false'\n",
    "    }\n",
    "    response = session.get(url, headers=headers)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "responses = []\n",
    "for row in tqdm(reduced_df.itertuples(), total=len(reduced_df)):\n",
    "    first_day = datetime.today().replace(day=1).strftime('%Y-%m-%d')\n",
    "    response = get_schedules(first_day, int(row.pol_code), int(row.pod_code))\n",
    "    responses.append(response)\n",
    "    time.sleep(random.randint(2,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relevant_fields(response, i):\n",
    "    return {\n",
    "        'pol_code': response.json()[0]['Sailings'][i]['PortOfLoadId'],\n",
    "        'pod_code': response.json()[0]['Sailings'][i]['PortOfDischargeId'],\n",
    "        'Voyage': response.json()[0]['Sailings'][i]['VoyageNum'],\n",
    "        'Vessel': response.json()[0]['Sailings'][i]['VesselName'],\n",
    "        'updated_etd': response.json()[0]['Sailings'][i]['NextETD'],\n",
    "        'updated_eta': response.json()[0]['Sailings'][i]['ArrivalDate']\n",
    "    }\n",
    "\n",
    "response_df = pd.DataFrame(([get_relevant_fields(response, i)\n",
    "                             for response in responses\n",
    "                             for i in range(len(response.json()[0]['Sailings']))\n",
    "                            ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create reverse mapping from port_code to name\n",
    "msc_port_id_reversed = {v:k for k,v in msc_port_id.items()}\n",
    "\n",
    "# Add additional columns to response_df\n",
    "response_df['pol_name'] = response_df.pol_code.map(msc_port_id_reversed)\n",
    "response_df['pod_name'] = response_df.pod_code.map(msc_port_id_reversed)\n",
    "\n",
    "# Merge results back to original dataframe\n",
    "merge_key = ['pol_name', 'pod_name', 'Vessel', 'Voyage']\n",
    "msc_delay_sheet = msc_delay_sheet.merge(response_df[merge_key + ['updated_eta', 'updated_etd']], on=merge_key, how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSC Arrival-Departure API\n",
    "Not currently in use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def json_payload(port_of_loading):\n",
    "#     return {\n",
    "#         'mscCode': port_of_loading,\n",
    "#         'isCountry': False\n",
    "#     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = \"https://www.msc.com/Site/WebServices/RouteFinder.svc/PortActivity\"\n",
    "# payload = {\n",
    "#     'mscCode': 'NZBLU',\n",
    "#     'isCountry': False\n",
    "# }\n",
    "# headers = {\n",
    "#     'Accept': '*/*',\n",
    "#     'X-Requested-With': 'XMLHttpRequest',\n",
    "#     'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/84.0.4147.125 Safari/537.36',\n",
    "#     'Content-Type': 'application/json; charset=UTF-8',\n",
    "#     'Origin': 'https://www.msc.com',\n",
    "#     'Sec-Fetch-Site': 'same-origin',\n",
    "#     'Sec-Fetch-Mode': 'cors',\n",
    "#     'Sec-Fetch-Dest': 'empty',\n",
    "#     'Referer': 'https://www.msc.com/arrivals-departures',\n",
    "#     'Accept-Encoding': 'gzip, deflate, br',\n",
    "#     'Accept-Language': 'en-GB,en;q=0.9',\n",
    "#     'Cookie': 'CMSPreferredCulture=en-GB; ASP.NET_SessionId=tht5lkut0asln2goiskoagfe; UrlReferrer=https://www.google.com/; CurrentContact=8b0b2fea-705b-4a4f-b8bf-bb1cd6c982bc; CMSLandingPageLoaded=true; MSCAgencyId=115867; BIGipServerkentico.app~kentico_pool=439883018.20480.0000; _ga=GA1.2.1736073830.1597290148; _gid=GA1.2.1289141279.1597290148; _gcl_au=1.1.345060449.1597290148; __hstc=100935006.13bb76c8a78a8d0a203a993ffef3a3f6.1597290148282.1597290148282.1597290148282.1; __hssrc=1; hubspotutk=13bb76c8a78a8d0a203a993ffef3a3f6; _ym_uid=15972901491036911544; _ym_d=1597290149; _ym_isad=1; _ym_visorc_65601397=w; newsletter-signup-cookie=temp-hidden; _hjid=3e183004-f562-4048-8b60-daccdf9c187c; _hjUserAttributesHash=2c3b62a0e1cd48bdfd4d01b922060e19; _hjCachedUserAttributes={`\"attributes`\":{`\"mscAgencyId`\":`\"115867`\"},`\"userId`\":null}; OptanonAlertBoxClosed=2020-08-13T03:42:45.080Z; CMSCookieLevel=200; VisitorStatus=11062214903; CMSUserPage={`\"TimeStamp`\":`\"2020-08-13T05:43:28.7403678+02:00`\",`\"LastPageDocumentID`\":2969,`\"LastPageNodeID`\":6383,`\"Identifier`\":`\"93e5bd8e-a77a-49db-b00e-1e3712608ca2`\"}; TS0142aef9=0192b4b6225179b1baa3b4d270b71a4eee782a0192338173beabaa471f306c2a13fe854bf6a7ac08ac21924991864aa7728c54559023beabd273d82285d5f943202adb58da417d61813232e89b240828c090f890c6a74dc4adfec38513d13447be4b5b4404d69f964987b7917f731b858f0c9880a139994b98397c4aeb5bd60b0d0e38ec9e5f3c97b13fb184b4e068506e6086954f8a515f2b7239d2e5c1b9c70f61ca74f736355c58648a6036e9b5d06412389ac41221c5cb740df99c84dc2bfef4a530dbc5e2577c189212eebac723d9ee9f98030f4bc6ca7d824ab313ae5fdd1eaa9886; OptanonConsent=isIABGlobal=false&datestamp=Thu+Aug+13+2020+11%3A43%3A36+GMT%2B0800+(Singapore+Standard+Time)&version=5.9.0&landingPath=NotLandingPage&groups=1%3A1%2C2%3A1%2C3%3A1%2C4%3A1%2C0_53017%3A1%2C0_53020%3A1%2C0_53018%3A1%2C0_53019%3A1%2C101%3A1&AwaitingReconsent=false; _gat=1; _gat_local=1; __hssc=100935006.3.1597290148283; _gali=ui-id-2'\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# response = session.request(\"POST\", url, headers=headers, json=payload)\n",
    "# response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSCExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MSCExtractor:\n",
    "    def __init__(self, xl):\n",
    "        # Get the MSC delay sheet\n",
    "        self.delay_sheet = (xl.parse(pd.to_datetime(xl.sheet_names,\n",
    "                            errors='coerce',\n",
    "                            format='%d.%m.%Y').max().date().strftime('%d.%m.%Y'),\n",
    "                            parse_dates=True)\n",
    "                            .query(f\"`Fwd Agent` in {['MSC']}\"))\n",
    "        \n",
    "        # Get the MSC-specific port names from the UNLOCODEs\n",
    "        self.port_mapping = {v['Port Code']: v['MSC Port Name'] for k,v in (pd.read_excel('data/MSC Port Code Mapping.xlsx')\n",
    "                                                                   .to_dict('index').items())}\n",
    "        \n",
    "        # Get port name\n",
    "        self.delay_sheet = self.delay_sheet.assign(pol_name=lambda x: x['Port of Loading'].apply(lambda y: self.port_mapping.get(y)),\n",
    "                                                   pod_name=lambda x: x['Port of discharge'].apply(lambda y: self.port_mapping.get(y)))\n",
    "\n",
    "        self.session = requests.Session()\n",
    "        \n",
    "    def get_countryID(self):\n",
    "        def query_id(port):\n",
    "            url = f\"https://www.msc.com/api/schedules/autocomplete?q={port}\"\n",
    "            return self.session.request(\"GET\", url)\n",
    "\n",
    "        def get_id(response):\n",
    "            if len(response.json()):\n",
    "                return response.json()[0].get('id')\n",
    "            \n",
    "        msc_locations = list(self.delay_sheet.pol_name.unique()) + list(self.delay_sheet.pod_name.unique())\n",
    "        location_code_responses = {location: query_id(location) for location in tqdm(msc_locations)}\n",
    "        self.msc_port_id = {k:get_id(v) for k,v in location_code_responses.items()}\n",
    "        \n",
    "        # PODs with no pod_id\n",
    "        exception_cases = [k for k,v in self.msc_port_id.items() if v is None]\n",
    "        with open('msc_exceptions.txt', 'w') as msc_exceptions:\n",
    "            json.dump(exception_cases, msc_exceptions)\n",
    "        \n",
    "\n",
    "    def prepare(self):\n",
    "        # Further filter by POL-Vessel-Voyage to get ETD, POD-Vessel-Voyage to get ETA\n",
    "        key = ['pol_name', 'pod_name']\n",
    "        reduced_df = self.delay_sheet.drop_duplicates(key)[key].sort_values(key)\n",
    "\n",
    "        reduced_df['pol_code'] = reduced_df.pol_name.map(self.msc_port_id)\n",
    "        reduced_df['pod_code'] = reduced_df.pod_name.map(self.msc_port_id)\n",
    "\n",
    "        # Unable to handle those with no pod_id in MSC; dropping these lines\n",
    "        reduced_df.dropna(inplace=True)\n",
    "        self.reduced_df = reduced_df.copy()\n",
    "        \n",
    "    def call_api(self):\n",
    "        def get_schedules(etd, pol, pod):\n",
    "            url = f\"https://www.msc.com/api/schedules/search?WeeksOut=8&DirectRoutes=false&Date={etd}&From={pol}&To={pod}\"\n",
    "            headers = {\n",
    "                'Accept': 'application/json',\n",
    "                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/84.0.4147.105 Safari/537.36',\n",
    "                'Content-Type': 'application/json',\n",
    "                'Sec-Fetch-Site': 'same-origin',\n",
    "                'Sec-Fetch-Mode': 'cors',\n",
    "                'Sec-Fetch-Dest': 'empty',\n",
    "                'Referer': 'https://www.msc.com/search-schedules',\n",
    "                'Accept-Language': 'en-GB,en;q=0.9',\n",
    "                'Cookie': 'CMSPreferredCulture=en-GB; ASP.NET_SessionId=tht5lkut0asln2goiskoagfe; UrlReferrer=https://www.google.com/; CurrentContact=8b0b2fea-705b-4a4f-b8bf-bb1cd6c982bc; MSCAgencyId=115867; BIGipServerkentico.app~kentico_pool=439883018.20480.0000; _ga=GA1.2.1736073830.1597290148; _gid=GA1.2.1289141279.1597290148; _gcl_au=1.1.345060449.1597290148; __hstc=100935006.13bb76c8a78a8d0a203a993ffef3a3f6.1597290148282.1597290148282.1597290148282.1; hubspotutk=13bb76c8a78a8d0a203a993ffef3a3f6; __hssrc=1; _ym_uid=15972901491036911544; _ym_d=1597290149; _ym_isad=1; newsletter-signup-cookie=temp-hidden; _hjid=3e183004-f562-4048-8b60-daccdf9c187c; _hjUserAttributesHash=2c3b62a0e1cd48bdfd4d01b922060e19; _hjCachedUserAttributes={\"attributes\":{\"mscAgencyId\":\"115867\"},\"userId\":null}; OptanonAlertBoxClosed=2020-08-13T03:42:45.080Z; CMSCookieLevel=200; VisitorStatus=11062214903; TS0142aef9=0192b4b6225179b1baa3b4d270b71a4eee782a0192338173beabaa471f306c2a13fe854bf6a7ac08ac21924991864aa7728c54559023beabd273d82285d5f943202adb58da417d61813232e89b240828c090f890c6a74dc4adfec38513d13447be4b5b4404d69f964987b7917f731b858f0c9880a139994b98397c4aeb5bd60b0d0e38ec9e5f3c97b13fb184b4e068506e6086954f8a515f2b7239d2e5c1b9c70f61ca74f736355c58648a6036e9b5d06412389ac41221c5cb740df99c84dc2bfef4a530dbc5e2577c189212eebac723d9ee9f98030f4bc6ca7d824ab313ae5fdd1eaa9886; OptanonConsent=isIABGlobal=false&datestamp=Thu+Aug+13+2020+11%3A43%3A36+GMT%2B0800+(Singapore+Standard+Time)&version=5.9.0&landingPath=NotLandingPage&groups=1%3A1%2C2%3A1%2C3%3A1%2C4%3A1%2C0_53017%3A1%2C0_53020%3A1%2C0_53018%3A1%2C0_53019%3A1%2C101%3A1&AwaitingReconsent=false'\n",
    "            }\n",
    "            response = self.session.get(url, headers=headers)\n",
    "            return response\n",
    "        \n",
    "        self.responses = []\n",
    "        reduced_df = self.reduced_df\n",
    "        for row in tqdm(reduced_df.itertuples(), total=len(reduced_df)):\n",
    "            first_day = datetime.today().replace(day=1).strftime('%Y-%m-%d')\n",
    "            response = get_schedules(first_day, int(row.pol_code), int(row.pod_code))\n",
    "            self.responses.append(response)\n",
    "            time.sleep(random.randint(2,5))\n",
    "        \n",
    "    def assemble_data(self):\n",
    "        def get_relevant_fields(response, i):\n",
    "            return {\n",
    "                'pol_code': response.json()[0]['Sailings'][i]['PortOfLoadId'],\n",
    "                'pod_code': response.json()[0]['Sailings'][i]['PortOfDischargeId'],\n",
    "                'Voyage': response.json()[0]['Sailings'][i]['VoyageNum'],\n",
    "                'Vessel': response.json()[0]['Sailings'][i]['VesselName'],\n",
    "                'updated_etd': response.json()[0]['Sailings'][i]['NextETD'],\n",
    "                'updated_eta': response.json()[0]['Sailings'][i]['ArrivalDate']\n",
    "            }\n",
    "\n",
    "        response_df = pd.DataFrame(([get_relevant_fields(response, i)\n",
    "                                     for response in self.responses\n",
    "                                     for i in range(len(response.json()[0]['Sailings']))\n",
    "                                     if len(response.json())\n",
    "                                    ]))\n",
    "        \n",
    "        # Create reverse mapping from port_code to name\n",
    "        msc_port_id_reversed = {v:k for k,v in self.msc_port_id.items()}\n",
    "\n",
    "        # Add additional columns to response_df\n",
    "        response_df['pol_name'] = response_df.pol_code.map(msc_port_id_reversed)\n",
    "        response_df['pod_name'] = response_df.pod_code.map(msc_port_id_reversed)\n",
    "\n",
    "        # Merge results back to original dataframe\n",
    "        merge_key = ['pol_name', 'pod_name', 'Vessel', 'Voyage']\n",
    "        self.delay_sheet = self.delay_sheet.merge(response_df[merge_key + ['updated_eta', 'updated_etd']],\n",
    "                                                  on=merge_key, how='left')\n",
    "        \n",
    "        self.delay_sheet.updated_eta = pd.to_datetime(self.delay_sheet.updated_eta.str[:10])\n",
    "        self.delay_sheet.updated_etd = pd.to_datetime(self.delay_sheet.updated_etd.str[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### G2Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class G2Extractor:\n",
    "    def __init__(self, g2_file, xl):\n",
    "        self.schedule = pd.read_excel(\n",
    "            g2_file, skiprows=9, index_col='Unnamed: 0')\n",
    "        self.delay_sheet = (xl.parse(pd.to_datetime(xl.sheet_names,\n",
    "                                                    errors='coerce',\n",
    "                                                    format='%d.%m.%Y').max().date().strftime('%d.%m.%Y'),\n",
    "                                     parse_dates=True)\n",
    "                            .query(f\"`Fwd Agent` in {['G2OCEAN']}\"))\n",
    "        self.g2_port_map = {\n",
    "            'AUPTJ': 'Portland',\n",
    "            'AUNTL': 'Newcastle',\n",
    "            'AUGLT': 'Gladstone',\n",
    "            'NZTWI': 'Bluff',\n",
    "            'TWKHH': 'Kaohsiung',\n",
    "            'KRINC': 'Inchon',\n",
    "            'KRPUS': 'Busan',\n",
    "            'JPYOK': 'Yokohama',\n",
    "            'JPNGO': 'Nagoya',\n",
    "            'JPOSA': 'Osaka',\n",
    "            'JPTOY': 'Toyama',\n",
    "            'JPIHA': 'Niihama',\n",
    "            'HKHKG': 'Hong Kong',\n",
    "            'CNSHA': 'Shanghai'\n",
    "        }\n",
    "\n",
    "    def get_updated_etd(self, row):\n",
    "        try:\n",
    "            # column_index_etd is the column number that points to the ETD\n",
    "            column_index_etd = np.argwhere(\n",
    "                self.schedule.columns.str.contains(row['Vessel']))[0][0] + 1\n",
    "        except IndexError:\n",
    "            return np.nan\n",
    "        return self.schedule.loc[self.schedule.index == self.g2_port_map.get(row['Port of Loading'])].iloc[:, column_index_etd][0]\n",
    "\n",
    "    def get_updated_eta(self, row):\n",
    "        try:\n",
    "            # column_index_eta is the column number that points to the ETA\n",
    "            column_index_eta = np.argwhere(\n",
    "                self.schedule.columns.str.contains(row['Vessel']))[0][0]\n",
    "        except IndexError:\n",
    "            return np.nan\n",
    "        return self.schedule.loc[self.schedule.index == self.g2_port_map.get(row['Port of discharge'])].iloc[:, column_index_eta][0]\n",
    "\n",
    "    def extract(self):\n",
    "        self.delay_sheet['updated_etd'] = self.delay_sheet.apply(self.get_updated_etd, axis=1)\n",
    "        self.delay_sheet['updated_eta'] = self.delay_sheet.apply(self.get_updated_eta, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DelayReport:\n",
    "    def __init__(self):\n",
    "        # Read configuration file\n",
    "        with open(\"data/config.json\", \"r\") as f:\n",
    "            self.config = json.load(f)\n",
    "            \n",
    "        # Used to map carrier names to the ones BigSchedules uses and supports\n",
    "        with open(\"data/carrier_mapping.json\", \"r\") as f:\n",
    "            self.carrier_mapping = json.load(f)\n",
    "        \n",
    "        # BigSchedules login\n",
    "        with open(\"data/bigschedules_login.json\", \"r\") as f:\n",
    "            self.bs_login = json.load(f)\n",
    "        \n",
    "        # Prepare base information\n",
    "        # UNLOCODE to port name mapping\n",
    "        self.port_mapping = (\n",
    "            pd.concat([pd.read_csv(p, usecols=[1, 2, 4, 5], engine='python', names=[\n",
    "                      'country', 'port', 'name', 'subdiv']) for p in Path('data').glob(\"*UNLOCODE CodeListPart*\")])\n",
    "            .query('port == port')\n",
    "            .assign(uncode=lambda x: x.country.str.cat(x.port),\n",
    "                    full_name=lambda x: np.where(x.subdiv.notnull(), x.name.str.cat(x.subdiv, sep=\", \"), x.name))\n",
    "            .drop_duplicates('uncode')\n",
    "            .set_index('uncode')\n",
    "            .to_dict('index'))\n",
    "        \n",
    "        # Read the vessel delay tracking file\n",
    "        self.xl = pd.ExcelFile(self.config['delay_filename'])\n",
    "        # today_date = datetime.now().strftime('%d.%m.%Y')\n",
    "        # if today_date not in self.xl.sheet_names:\n",
    "        #     raise Exception(\n",
    "        #         f\"The script cannot find today's date ({today_date}) in the Vessel Delay Tracking.xlsx file provided. Please check that the sheets are correctly named - the script will only operate on a sheet with today's date.\")\n",
    "        \n",
    "    def run_bs(self):\n",
    "        if self.config.get('run_bs'):\n",
    "            bs_extractor = BSExtractor()\n",
    "            bs_extractor.extract()\n",
    "        \n",
    "    def run_msc(self):\n",
    "        if self.config.get('run_msc'):\n",
    "            self.msc_extractor = MSCExtractor(self.xl)\n",
    "            self.msc_extractor.get_countryID()\n",
    "            self.msc_extractor.prepare()\n",
    "            self.msc_extractor.call_api()\n",
    "            self.msc_extractor.assemble_data()\n",
    "    \n",
    "    def run_g2(self):\n",
    "        if self.config.get('run_g2'):\n",
    "            self.g2_extractor = G2Extractor(self.config.get('g2_filename'), self.xl)\n",
    "            self.g2_extractor.extract()\n",
    "    \n",
    "    def assemble(self):\n",
    "        # Assemble the final dataframe to update\n",
    "        main_delay_sheet = self.xl.parse()\n",
    "\n",
    "        # If our current Excel file already has an updated_eta or updated_etd columns, we drop them\n",
    "        for updated_column in ['updated_eta', 'updated_etd']:\n",
    "            if updated_column in main_delay_sheet.columns:\n",
    "                main_delay_sheet.drop(updated_column, axis=1, inplace=True)\n",
    "        \n",
    "        # Add new columns to the right side of the dataframe\n",
    "        new_columns = ['updated_etd', 'updated_eta', 'No. of days delayed ETD', 'No. of days delayed ETA', 'Reason of Delay']\n",
    "        main_delay_sheet[new_columns] = pd.DataFrame([[pd.NaT for i in range(4)] + [np.nan]])\n",
    "\n",
    "        if self.config.get('run_bs'):\n",
    "            main_delay_sheet.update(self.bs_extractor.delay_sheet)\n",
    "        \n",
    "        if self.config.get('run_msc'):\n",
    "            main_delay_sheet.update(self.msc_extractor.delay_sheet)\n",
    "        \n",
    "        if self.config.get('run_g2'):\n",
    "            main_delay_sheet.update(self.g2_extractor.delay_sheet)\n",
    "\n",
    "        # Calculate the deltas\n",
    "        main_delay_sheet['No. of days delayed ETD'] = (main_delay_sheet.updated_etd\n",
    "                                                       - pd.to_datetime(main_delay_sheet['ETD Date'])).dt.days\n",
    "        main_delay_sheet['No. of days delayed ETA'] = (main_delay_sheet.updated_eta\n",
    "                                                       - pd.to_datetime(main_delay_sheet['Disport ETA'])).dt.days\n",
    "\n",
    "        # Format the dates correctly via strftime\n",
    "        date_columns = ['ETD Date', 'Disport ETA', 'updated_etd', 'updated_eta']\n",
    "        for column in date_columns:\n",
    "            main_delay_sheet[column] = main_delay_sheet[column].dt.strftime('%d/%m/%Y')\n",
    "        self.main_delay_sheet = main_delay_sheet.copy()\n",
    "    \n",
    "    def output(self):\n",
    "        # Output the excel file\n",
    "        saved_file = f\"Vessel Delay Tracking - {datetime.today().strftime('%d.%m.%Y')}.xlsx\"\n",
    "        self.main_delay_sheet.to_excel(saved_file)\n",
    "        os.startfile(saved_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delay report skeleton\n",
    "delay_report = DelayReport()\n",
    "delay_report.run_bs()\n",
    "delay_report.run_msc()\n",
    "delay_report.run_g2()\n",
    "delay_report.assemble()\n",
    "delay_report.output()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
