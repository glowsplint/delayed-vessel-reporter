{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delay Report\n",
    "### Overview\n",
    "The delay report script aims to find the updated_eta and updated_etd of certain vessels provided within \"Vessel Delay Tracking.XLSX\". This is done by querying an underlying BigSchedules API, MSC Web API and from a static G2 Schedules Excel document. None of the API interactions use the Rio Tinto credentials to ensure that traceback cannot occur.\n",
    "\n",
    "The script is written in a modular approach to increase ease of maintenance and improve code quality. Configurations are stored in a `data` subdirectory. The script expects a `Vessel Delay Tracking.XLSX` file and `g2_filename` (G2 Schedule Excel file) in the same directory.\n",
    "\n",
    "### Features\n",
    "1. Avoids detection\n",
    "    - Uses API calls instead of Selenium which is easily detectable\n",
    "    - Uses randomised timing for API requests\n",
    "2. Modular\n",
    "    - If one component breaks, you can always disable it without affecting the other modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "import time\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from pathlib import Path\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "# pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions\n",
    "def write_json(response: dict, output_file: str):\n",
    "    with open(output_file, 'w') as w:\n",
    "        json.dump(response, w, indent=2)\n",
    "\n",
    "def read_config(instance: object, attr_name: str, path_to_config: str):\n",
    "    with open(path_to_config, \"r\") as f:\n",
    "        setattr(instance, attr_name, json.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read configuration file\n",
    "with open(\"data/config.json\", \"r\") as f:\n",
    "    config = json.load(f)\n",
    "    \n",
    "# Used to map carrier names to the ones BigSchedule uses and supports\n",
    "with open(\"data/carrier_mapping.json\", \"r\") as f:\n",
    "    carrier_mapping = json.load(f)\n",
    "\n",
    "# Bigschedule login\n",
    "with open(\"data/bigschedules_login.json\", \"r\") as f:\n",
    "    bs_login = json.load(f)\n",
    "    \n",
    "# Prepare base information\n",
    "# UNLOCODE to port name mapping\n",
    "port_mapping = (\n",
    "    pd.concat([pd.read_csv(p, usecols=[1, 2, 4, 5], engine='python', names=[\n",
    "              'country', 'port', 'name', 'subdiv']) for p in Path('data').glob(\"*UNLOCODE CodeListPart*\")])\n",
    "    .query('port == port')\n",
    "    .assign(\n",
    "        uncode=lambda x: x.country.str.cat(x.port),\n",
    "        full_name=lambda x: np.where(\n",
    "            x.subdiv.notnull(), x.name.str.cat(x.subdiv, sep=\", \"), x.name)\n",
    "    )\n",
    "    .drop_duplicates('uncode')\n",
    "    .set_index('uncode')\n",
    "    .to_dict('index')\n",
    ")\n",
    "\n",
    "# Read the vessel delay tracking file\n",
    "xl = pd.ExcelFile('Vessel Delay Tracking.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BSExtractor\n",
    "To use the BigSchedules Web API, we first need to query sub-APIs to get all the information we need to query the main API.\n",
    "These parameters and their corresponding sub-APIs are:\n",
    "\n",
    "1. `_` : YYYYMMDDHH (24h)\n",
    "2. `carrierId`: GET from https://www.bigschedules.com/api/carrier/fuzzyQuery\n",
    "3. `scac`: GET from https://www.bigschedules.com/api/carrier/fuzzyQuery\n",
    "4. `vesselGid`: GET from https://www.bigschedules.com/api/vessel/list?_=2020081916&vesselName=maersk+danube; this query also requires timestamp\n",
    "\n",
    "Only after we query these sub-APIs, do we have the parameter values to query the web API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigschedules_sheet = (\n",
    "    xl.parse(pd.to_datetime(xl.sheet_names,\n",
    "                            errors='coerce',\n",
    "                            format='%d.%m.%Y').max().date().strftime('%d.%m.%Y'),\n",
    "                            parse_dates=True)\n",
    "                            .query(f\"`Fwd Agent` in {[k for k,v in carrier_mapping.items()]}\")\n",
    "                            .replace({'Fwd Agent': carrier_mapping})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get port name\n",
    "bigschedules_sheet = bigschedules_sheet.assign(pol_name=lambda x: x['Port of Loading'].apply(lambda y: port_mapping.get(y)['name']),\n",
    "                                               pod_name=lambda x: x['Port of discharge'].apply(lambda y: port_mapping.get(y)['name']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Plnt</th>\n",
       "      <th>Req. Delivery Date</th>\n",
       "      <th>Shipment</th>\n",
       "      <th>Term</th>\n",
       "      <th>Sold-to-Party Name</th>\n",
       "      <th>Ship-to-Pty</th>\n",
       "      <th>Sales Ord.</th>\n",
       "      <th>Delivery</th>\n",
       "      <th>Description</th>\n",
       "      <th>Product Type</th>\n",
       "      <th>Vessel</th>\n",
       "      <th>Voyage</th>\n",
       "      <th>ETD Date</th>\n",
       "      <th>Disport ETA</th>\n",
       "      <th>Gross Weight</th>\n",
       "      <th>Port of Loading</th>\n",
       "      <th>Port of discharge</th>\n",
       "      <th>Incoterms Part2</th>\n",
       "      <th>No. of Containers</th>\n",
       "      <th>Container Type</th>\n",
       "      <th>MetPro Status</th>\n",
       "      <th>Fwd Agent</th>\n",
       "      <th>Booking Ref.</th>\n",
       "      <th>Reason for rejection description</th>\n",
       "      <th>No. of bundles</th>\n",
       "      <th>Item Status Information</th>\n",
       "      <th>Incoterms Part1</th>\n",
       "      <th>Shipping Cond</th>\n",
       "      <th>updated_etd</th>\n",
       "      <th>updated_eta</th>\n",
       "      <th>No. of days delayed ETD</th>\n",
       "      <th>No. of days delayed ETA</th>\n",
       "      <th>Reason of Delay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2502</td>\n",
       "      <td>2020-08-10</td>\n",
       "      <td>30012791.0</td>\n",
       "      <td>4050</td>\n",
       "      <td>SHENG YU STEEL CO. LTD.</td>\n",
       "      <td>SHENGYU</td>\n",
       "      <td>15018188</td>\n",
       "      <td>802094756</td>\n",
       "      <td>TA 480 X 840 AA941.1 1182 ANY N</td>\n",
       "      <td>TA</td>\n",
       "      <td>COSCO INDONESIA</td>\n",
       "      <td>095N</td>\n",
       "      <td>2020-08-20</td>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>158.426</td>\n",
       "      <td>AUMEL</td>\n",
       "      <td>TWKHH</td>\n",
       "      <td>KAOHSIUNG, TAIWAN</td>\n",
       "      <td>7</td>\n",
       "      <td>TEU</td>\n",
       "      <td>SHIPPED</td>\n",
       "      <td>ANL</td>\n",
       "      <td>AEL0985436</td>\n",
       "      <td>NaN</td>\n",
       "      <td>140</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CIF</td>\n",
       "      <td>31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2501</td>\n",
       "      <td>2020-07-15</td>\n",
       "      <td>30012670.0</td>\n",
       "      <td>6140</td>\n",
       "      <td>HIHO METAL CO., LTD.</td>\n",
       "      <td>HIHO</td>\n",
       "      <td>15017843</td>\n",
       "      <td>802093896</td>\n",
       "      <td>IS 22KG AA170.9 CNTR 44 N</td>\n",
       "      <td>IS</td>\n",
       "      <td>CHRISTA SCHULTE</td>\n",
       "      <td>004N</td>\n",
       "      <td>2020-08-08</td>\n",
       "      <td>2020-08-23</td>\n",
       "      <td>509.705</td>\n",
       "      <td>AUBNE</td>\n",
       "      <td>KRBNP</td>\n",
       "      <td>BUSAN NEW PORT, KOREA</td>\n",
       "      <td>21</td>\n",
       "      <td>CNO</td>\n",
       "      <td>SHIPPED</td>\n",
       "      <td>HAPAG</td>\n",
       "      <td>43888731</td>\n",
       "      <td>NaN</td>\n",
       "      <td>504</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CIF</td>\n",
       "      <td>31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2501</td>\n",
       "      <td>2020-07-15</td>\n",
       "      <td>30012688.0</td>\n",
       "      <td>6140</td>\n",
       "      <td>HIHO METAL CO., LTD.</td>\n",
       "      <td>HIHO</td>\n",
       "      <td>15017848</td>\n",
       "      <td>802093901</td>\n",
       "      <td>IS 22KG AA170.9 CNTR 44 N</td>\n",
       "      <td>IS</td>\n",
       "      <td>CHRISTA SCHULTE</td>\n",
       "      <td>004N</td>\n",
       "      <td>2020-08-08</td>\n",
       "      <td>2020-08-17</td>\n",
       "      <td>484.451</td>\n",
       "      <td>AUBNE</td>\n",
       "      <td>KRBNP</td>\n",
       "      <td>BUSAN NEW PORT, KOREA</td>\n",
       "      <td>20</td>\n",
       "      <td>CNO</td>\n",
       "      <td>SHIPPED</td>\n",
       "      <td>EVERGREEN</td>\n",
       "      <td>600000015375</td>\n",
       "      <td>NaN</td>\n",
       "      <td>480</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CIF</td>\n",
       "      <td>31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2522</td>\n",
       "      <td>2020-07-15</td>\n",
       "      <td>30012647.0</td>\n",
       "      <td>400A</td>\n",
       "      <td>OHGITANI CORPORATION</td>\n",
       "      <td>NISC</td>\n",
       "      <td>15017964</td>\n",
       "      <td>802093833</td>\n",
       "      <td>TA 480 X 840 XA941.1 1000 US ANY N</td>\n",
       "      <td>TA</td>\n",
       "      <td>OOCL SHANGHAI</td>\n",
       "      <td>053N</td>\n",
       "      <td>2020-08-01</td>\n",
       "      <td>2020-08-20</td>\n",
       "      <td>262.523</td>\n",
       "      <td>AUMEL</td>\n",
       "      <td>JPOSA</td>\n",
       "      <td>OSAKA, JAPAN</td>\n",
       "      <td>11</td>\n",
       "      <td>TEU</td>\n",
       "      <td>SHIPPED</td>\n",
       "      <td>ANL</td>\n",
       "      <td>AEL0974951</td>\n",
       "      <td>NaN</td>\n",
       "      <td>275</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DDP</td>\n",
       "      <td>31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2522</td>\n",
       "      <td>2020-07-15</td>\n",
       "      <td>30012647.0</td>\n",
       "      <td>400A</td>\n",
       "      <td>OHGITANI CORPORATION</td>\n",
       "      <td>NISC</td>\n",
       "      <td>15017965</td>\n",
       "      <td>802093834</td>\n",
       "      <td>TA 480 X 840 XA941.1 1000 US ANY N</td>\n",
       "      <td>TA</td>\n",
       "      <td>OOCL SHANGHAI</td>\n",
       "      <td>053N</td>\n",
       "      <td>2020-08-01</td>\n",
       "      <td>2020-08-18</td>\n",
       "      <td>214.673</td>\n",
       "      <td>AUMEL</td>\n",
       "      <td>JPYOK</td>\n",
       "      <td>Yokohama, Japan</td>\n",
       "      <td>9</td>\n",
       "      <td>TEU</td>\n",
       "      <td>SHIPPED</td>\n",
       "      <td>ANL</td>\n",
       "      <td>AEL0974918</td>\n",
       "      <td>NaN</td>\n",
       "      <td>225</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DDP</td>\n",
       "      <td>31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>2524</td>\n",
       "      <td>2020-08-20</td>\n",
       "      <td>30012866.0</td>\n",
       "      <td>400A</td>\n",
       "      <td>FUJIDEN INTERNATIONAL CORP.</td>\n",
       "      <td>YODOGAWA</td>\n",
       "      <td>15018354</td>\n",
       "      <td>802094914</td>\n",
       "      <td>BK 300 X 865 410370 1750 US</td>\n",
       "      <td>BK</td>\n",
       "      <td>RDO CONCERT</td>\n",
       "      <td>035N</td>\n",
       "      <td>2020-08-30</td>\n",
       "      <td>2020-09-23</td>\n",
       "      <td>147.240</td>\n",
       "      <td>AUSYD</td>\n",
       "      <td>JPOSA</td>\n",
       "      <td>KURE PLANT</td>\n",
       "      <td>6</td>\n",
       "      <td>CNO</td>\n",
       "      <td>ORDERED</td>\n",
       "      <td>HAMBURG</td>\n",
       "      <td>0BNE007342</td>\n",
       "      <td>NaN</td>\n",
       "      <td>120</td>\n",
       "      <td>O</td>\n",
       "      <td>DAP</td>\n",
       "      <td>31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>2504</td>\n",
       "      <td>2020-08-31</td>\n",
       "      <td>30012838.0</td>\n",
       "      <td>4200</td>\n",
       "      <td>HONDA METAL INDUSTRIES VIETNAM, LTD.</td>\n",
       "      <td>HONDAVN</td>\n",
       "      <td>15018259</td>\n",
       "      <td>802094842</td>\n",
       "      <td>BT 203 6063962 5800 4/4 H3</td>\n",
       "      <td>BT</td>\n",
       "      <td>ANL GIPPSLAND</td>\n",
       "      <td>046N</td>\n",
       "      <td>2020-08-31</td>\n",
       "      <td>2020-09-30</td>\n",
       "      <td>145.296</td>\n",
       "      <td>AUSYD</td>\n",
       "      <td>VNCLI</td>\n",
       "      <td>CAT LAI, VIETNAM</td>\n",
       "      <td>6</td>\n",
       "      <td>CNO</td>\n",
       "      <td>ORDERED</td>\n",
       "      <td>OOCL</td>\n",
       "      <td>4050311650</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72</td>\n",
       "      <td>O/ETA 15-25/09/2020</td>\n",
       "      <td>CIF</td>\n",
       "      <td>31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>2501</td>\n",
       "      <td>2020-08-30</td>\n",
       "      <td>30012857.0</td>\n",
       "      <td>4020</td>\n",
       "      <td>TRAFIGURA PTE LTD</td>\n",
       "      <td>ACCESSWKR</td>\n",
       "      <td>15018498</td>\n",
       "      <td>802095184</td>\n",
       "      <td>IS 22KG AA170.9 CNTR 44 N</td>\n",
       "      <td>IS</td>\n",
       "      <td>COSCO HONG KONG</td>\n",
       "      <td>152N</td>\n",
       "      <td>2020-08-31</td>\n",
       "      <td>2020-09-16</td>\n",
       "      <td>501.904</td>\n",
       "      <td>AUBNE</td>\n",
       "      <td>KRINC</td>\n",
       "      <td>INCHEON, KOREA</td>\n",
       "      <td>26</td>\n",
       "      <td>C20</td>\n",
       "      <td>ORDERED</td>\n",
       "      <td>OOCL</td>\n",
       "      <td>4050357730</td>\n",
       "      <td>NaN</td>\n",
       "      <td>494</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CIF</td>\n",
       "      <td>31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>2501</td>\n",
       "      <td>2020-08-30</td>\n",
       "      <td>30012857.0</td>\n",
       "      <td>4020</td>\n",
       "      <td>TRAFIGURA PTE LTD</td>\n",
       "      <td>ACCESSWKR</td>\n",
       "      <td>15018499</td>\n",
       "      <td>802095185</td>\n",
       "      <td>IS 22KG AA170.9 CNTR 44 N</td>\n",
       "      <td>IS</td>\n",
       "      <td>COSCO HONG KONG</td>\n",
       "      <td>152N</td>\n",
       "      <td>2020-08-31</td>\n",
       "      <td>2020-09-16</td>\n",
       "      <td>501.904</td>\n",
       "      <td>AUBNE</td>\n",
       "      <td>KRINC</td>\n",
       "      <td>INCHEON, KOREA</td>\n",
       "      <td>26</td>\n",
       "      <td>C20</td>\n",
       "      <td>ORDERED</td>\n",
       "      <td>OOCL</td>\n",
       "      <td>4050357780</td>\n",
       "      <td>NaN</td>\n",
       "      <td>494</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CIF</td>\n",
       "      <td>31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>2504</td>\n",
       "      <td>2020-08-30</td>\n",
       "      <td>30012843.0</td>\n",
       "      <td>4050</td>\n",
       "      <td>BLUEQUEST RESOURCES (OVERSEAS) LTD.</td>\n",
       "      <td>BLUEQUESBR</td>\n",
       "      <td>15018471</td>\n",
       "      <td>802095161</td>\n",
       "      <td>BT 178 6063T 5801 6/6 H3</td>\n",
       "      <td>BT</td>\n",
       "      <td>CMA CGM LOIRE</td>\n",
       "      <td>033N</td>\n",
       "      <td>2020-09-01</td>\n",
       "      <td>2020-10-20</td>\n",
       "      <td>205.744</td>\n",
       "      <td>AUSYD</td>\n",
       "      <td>BRIOA</td>\n",
       "      <td>ITAPOA, BRAZIL</td>\n",
       "      <td>8</td>\n",
       "      <td>B26</td>\n",
       "      <td>ORDERED</td>\n",
       "      <td>HAMBURG</td>\n",
       "      <td>0BNE006955</td>\n",
       "      <td>NaN</td>\n",
       "      <td>88</td>\n",
       "      <td>O</td>\n",
       "      <td>CFR</td>\n",
       "      <td>31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>140 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Plnt Req. Delivery Date    Shipment  Term  \\\n",
       "0    2502         2020-08-10  30012791.0  4050   \n",
       "1    2501         2020-07-15  30012670.0  6140   \n",
       "2    2501         2020-07-15  30012688.0  6140   \n",
       "3    2522         2020-07-15  30012647.0  400A   \n",
       "4    2522         2020-07-15  30012647.0  400A   \n",
       "..    ...                ...         ...   ...   \n",
       "298  2524         2020-08-20  30012866.0  400A   \n",
       "299  2504         2020-08-31  30012838.0  4200   \n",
       "300  2501         2020-08-30  30012857.0  4020   \n",
       "301  2501         2020-08-30  30012857.0  4020   \n",
       "304  2504         2020-08-30  30012843.0  4050   \n",
       "\n",
       "                       Sold-to-Party Name Ship-to-Pty  Sales Ord.   Delivery  \\\n",
       "0                 SHENG YU STEEL CO. LTD.     SHENGYU    15018188  802094756   \n",
       "1                    HIHO METAL CO., LTD.        HIHO    15017843  802093896   \n",
       "2                    HIHO METAL CO., LTD.        HIHO    15017848  802093901   \n",
       "3                    OHGITANI CORPORATION        NISC    15017964  802093833   \n",
       "4                    OHGITANI CORPORATION        NISC    15017965  802093834   \n",
       "..                                    ...         ...         ...        ...   \n",
       "298           FUJIDEN INTERNATIONAL CORP.    YODOGAWA    15018354  802094914   \n",
       "299  HONDA METAL INDUSTRIES VIETNAM, LTD.     HONDAVN    15018259  802094842   \n",
       "300                     TRAFIGURA PTE LTD   ACCESSWKR    15018498  802095184   \n",
       "301                     TRAFIGURA PTE LTD   ACCESSWKR    15018499  802095185   \n",
       "304   BLUEQUEST RESOURCES (OVERSEAS) LTD.  BLUEQUESBR    15018471  802095161   \n",
       "\n",
       "                            Description Product Type           Vessel Voyage  \\\n",
       "0       TA 480 X 840 AA941.1 1182 ANY N           TA  COSCO INDONESIA   095N   \n",
       "1             IS 22KG AA170.9 CNTR 44 N           IS  CHRISTA SCHULTE   004N   \n",
       "2             IS 22KG AA170.9 CNTR 44 N           IS  CHRISTA SCHULTE   004N   \n",
       "3    TA 480 X 840 XA941.1 1000 US ANY N           TA    OOCL SHANGHAI   053N   \n",
       "4    TA 480 X 840 XA941.1 1000 US ANY N           TA    OOCL SHANGHAI   053N   \n",
       "..                                  ...          ...              ...    ...   \n",
       "298         BK 300 X 865 410370 1750 US           BK      RDO CONCERT   035N   \n",
       "299          BT 203 6063962 5800 4/4 H3           BT    ANL GIPPSLAND   046N   \n",
       "300           IS 22KG AA170.9 CNTR 44 N           IS  COSCO HONG KONG   152N   \n",
       "301           IS 22KG AA170.9 CNTR 44 N           IS  COSCO HONG KONG   152N   \n",
       "304            BT 178 6063T 5801 6/6 H3           BT    CMA CGM LOIRE   033N   \n",
       "\n",
       "      ETD Date Disport ETA  Gross Weight Port of Loading Port of discharge  \\\n",
       "0   2020-08-20  2020-09-02       158.426           AUMEL             TWKHH   \n",
       "1   2020-08-08  2020-08-23       509.705           AUBNE             KRBNP   \n",
       "2   2020-08-08  2020-08-17       484.451           AUBNE             KRBNP   \n",
       "3   2020-08-01  2020-08-20       262.523           AUMEL             JPOSA   \n",
       "4   2020-08-01  2020-08-18       214.673           AUMEL             JPYOK   \n",
       "..         ...         ...           ...             ...               ...   \n",
       "298 2020-08-30  2020-09-23       147.240           AUSYD             JPOSA   \n",
       "299 2020-08-31  2020-09-30       145.296           AUSYD             VNCLI   \n",
       "300 2020-08-31  2020-09-16       501.904           AUBNE             KRINC   \n",
       "301 2020-08-31  2020-09-16       501.904           AUBNE             KRINC   \n",
       "304 2020-09-01  2020-10-20       205.744           AUSYD             BRIOA   \n",
       "\n",
       "           Incoterms Part2  No. of Containers Container Type MetPro Status  \\\n",
       "0        KAOHSIUNG, TAIWAN                  7            TEU       SHIPPED   \n",
       "1    BUSAN NEW PORT, KOREA                 21            CNO       SHIPPED   \n",
       "2    BUSAN NEW PORT, KOREA                 20            CNO       SHIPPED   \n",
       "3             OSAKA, JAPAN                 11            TEU       SHIPPED   \n",
       "4          Yokohama, Japan                  9            TEU       SHIPPED   \n",
       "..                     ...                ...            ...           ...   \n",
       "298             KURE PLANT                  6            CNO       ORDERED   \n",
       "299       CAT LAI, VIETNAM                  6            CNO       ORDERED   \n",
       "300         INCHEON, KOREA                 26            C20       ORDERED   \n",
       "301         INCHEON, KOREA                 26            C20       ORDERED   \n",
       "304         ITAPOA, BRAZIL                  8            B26       ORDERED   \n",
       "\n",
       "     Fwd Agent  Booking Ref.  Reason for rejection description  \\\n",
       "0          ANL    AEL0985436                               NaN   \n",
       "1        HAPAG      43888731                               NaN   \n",
       "2    EVERGREEN  600000015375                               NaN   \n",
       "3          ANL    AEL0974951                               NaN   \n",
       "4          ANL    AEL0974918                               NaN   \n",
       "..         ...           ...                               ...   \n",
       "298    HAMBURG    0BNE007342                               NaN   \n",
       "299       OOCL    4050311650                               NaN   \n",
       "300       OOCL    4050357730                               NaN   \n",
       "301       OOCL    4050357780                               NaN   \n",
       "304    HAMBURG    0BNE006955                               NaN   \n",
       "\n",
       "     No. of bundles Item Status Information Incoterms Part1  Shipping Cond  \\\n",
       "0               140                     NaN             CIF             31   \n",
       "1               504                     NaN             CIF             31   \n",
       "2               480                     NaN             CIF             31   \n",
       "3               275                     NaN             DDP             31   \n",
       "4               225                     NaN             DDP             31   \n",
       "..              ...                     ...             ...            ...   \n",
       "298             120                       O             DAP             31   \n",
       "299              72     O/ETA 15-25/09/2020             CIF             31   \n",
       "300             494                     NaN             CIF             31   \n",
       "301             494                     NaN             CIF             31   \n",
       "304              88                       O             CFR             31   \n",
       "\n",
       "     updated_etd  updated_eta  No. of days delayed ETD  \\\n",
       "0            NaN          NaN                      NaN   \n",
       "1            NaN          NaN                      NaN   \n",
       "2            NaN          NaN                      NaN   \n",
       "3            NaN          NaN                      NaN   \n",
       "4            NaN          NaN                      NaN   \n",
       "..           ...          ...                      ...   \n",
       "298          NaN          NaN                      NaN   \n",
       "299          NaN          NaN                      NaN   \n",
       "300          NaN          NaN                      NaN   \n",
       "301          NaN          NaN                      NaN   \n",
       "304          NaN          NaN                      NaN   \n",
       "\n",
       "     No. of days delayed ETA  Reason of Delay  \n",
       "0                        NaN              NaN  \n",
       "1                        NaN              NaN  \n",
       "2                        NaN              NaN  \n",
       "3                        NaN              NaN  \n",
       "4                        NaN              NaN  \n",
       "..                       ...              ...  \n",
       "298                      NaN              NaN  \n",
       "299                      NaN              NaN  \n",
       "300                      NaN              NaN  \n",
       "301                      NaN              NaN  \n",
       "304                      NaN              NaN  \n",
       "\n",
       "[140 rows x 33 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigschedules_sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BSExtractor:\n",
    "    \"\"\"\n",
    "    Extracts information from the BigSchedules Portal.\n",
    "    \n",
    "    Methods\n",
    "    -------\n",
    "    prepare:\n",
    "        A single query to the BigSchedules Web API can provide information to multiple lines on the delay_sheet.\n",
    "        Further filters self.delay_sheet to a smaller list of searches needed to fulfill all the lines on the\n",
    "            delay_sheet. This reduces the total number of calls made to the BigSchedules Web API and prevents\n",
    "            duplication of API calls.\n",
    "        \n",
    "    call_api:\n",
    "        Makes calls to the BigSchedules Web API, using information from the prepare method as parameters in the\n",
    "        API request. Also saves the API responses into a subdirectory \"responses/<today_date>\".\n",
    "    \n",
    "    extract:\n",
    "        Extracts information from the JSON responses from the call_api method and assembles the final dataframe.\n",
    "    \"\"\"\n",
    "    def __init__(self, main_delay_sheet: pd.DataFrame, interval: tuple):\n",
    "        # Get the BigSchedules delay sheet\n",
    "        self.delay_sheet = (main_delay_sheet.query(f\"`Fwd Agent` not in {['MSC', 'G2OCEAN']}\")\n",
    "                            .drop(['updated_etd', 'updated_eta', 'No. of days delayed ETD',\n",
    "                                   'No. of days delayed ETA', 'Reason of Delay'], axis=1)\n",
    "                            .copy())\n",
    "\n",
    "        # Get the BigSchedules-specific port names from the UNLOCODEs\n",
    "        self.port_mapping = (pd.concat([pd.read_csv(p, usecols=[1, 2, 4, 5], engine='python',\n",
    "                                               names=['country', 'port', 'name', 'subdiv']) for p in Path('data').glob(\"*UNLOCODE CodeListPart*\")])\n",
    "            .query('port == port')\n",
    "            .assign(\n",
    "                uncode=lambda x: x.country.str.cat(x.port),\n",
    "                full_name=lambda x: np.where(\n",
    "                    x.subdiv.notnull(), x.name.str.cat(x.subdiv, sep=\", \"), x.name)\n",
    "            )\n",
    "            .drop_duplicates('uncode')\n",
    "            .set_index('uncode')\n",
    "            .to_dict('index')\n",
    "        )\n",
    "        \n",
    "        # Get port name\n",
    "        self.delay_sheet = self.delay_sheet.assign(pol_name=lambda x: x['Port of Loading'].apply(lambda y: self.port_mapping.get(y)),\n",
    "                                                   pod_name=lambda x: x['Port of discharge'].apply(lambda y: self.port_mapping.get(y))).copy()\n",
    "\n",
    "        self.interval = interval\n",
    "        self.session = requests.Session()\n",
    "        \n",
    "    def prepare(self):\n",
    "        \"\"\"\n",
    "        Further filters self.delay_sheet to a smaller list of searches needed to fulfill all the lines on the\n",
    "            delay_sheet.\n",
    "        \"\"\"\n",
    "#         # Further filter by POL-Vessel-Voyage to get ETD, POD-Vessel-Voyage to get ETA\n",
    "#         key = ['pol_name', 'pod_name']\n",
    "#         self.reduced_df = self.delay_sheet.drop_duplicates(key)[key].sort_values(key)\n",
    "\n",
    "#         self.reduced_df['pol_code'] = self.reduced_df.pol_name.map(self.msc_port_id)\n",
    "#         self.reduced_df['pod_code'] = self.reduced_df.pod_name.map(self.msc_port_id)\n",
    "\n",
    "#         # Unable to handle those with no pod_id in BigSchedules Web; dropping these lines\n",
    "#         self.reduced_df.dropna(inplace=True)\n",
    "        \n",
    "    def call_api(self):\n",
    "        \"\"\"\n",
    "        Makes calls to the BigSchedules Web API, using information from the prepare method as parameters in the\n",
    "        API request. Also saves the API responses into a subdirectory \"responses/<today_date>\".\n",
    "        \"\"\"\n",
    "#         def get_schedules(etd: str, pol: str, pod: str):\n",
    "#             url = f\"https://www.bigschedules.com//api/vesselSchedule/list?DISABLE_ART=true&_=2020081917&carrierId=18&language=en-US&scac=HLCU&vesselGid=V000005557&vesselName=CHRISTA+SCHULTE\"\n",
    "#             headers = {\n",
    "#                 'Accept': 'application/json',\n",
    "#                 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/84.0.4147.105 Safari/537.36',\n",
    "#                 'Content-Type': 'application/json',\n",
    "#                 'Sec-Fetch-Site': 'same-origin',\n",
    "#                 'Sec-Fetch-Mode': 'cors',\n",
    "#                 'Sec-Fetch-Dest': 'empty',\n",
    "#                 'Referer': 'https://www.msc.com/search-schedules',\n",
    "#                 'Accept-Language': 'en-GB,en;q=0.9',\n",
    "#                 'Cookie': 'CMSPreferredCulture=en-GB; ASP.NET_SessionId=tht5lkut0asln2goiskoagfe; UrlReferrer=https://www.google.com/; CurrentContact=8b0b2fea-705b-4a4f-b8bf-bb1cd6c982bc; MSCAgencyId=115867; BIGipServerkentico.app~kentico_pool=439883018.20480.0000; _ga=GA1.2.1736073830.1597290148; _gid=GA1.2.1289141279.1597290148; _gcl_au=1.1.345060449.1597290148; __hstc=100935006.13bb76c8a78a8d0a203a993ffef3a3f6.1597290148282.1597290148282.1597290148282.1; hubspotutk=13bb76c8a78a8d0a203a993ffef3a3f6; __hssrc=1; _ym_uid=15972901491036911544; _ym_d=1597290149; _ym_isad=1; newsletter-signup-cookie=temp-hidden; _hjid=3e183004-f562-4048-8b60-daccdf9c187c; _hjUserAttributesHash=2c3b62a0e1cd48bdfd4d01b922060e19; _hjCachedUserAttributes={\"attributes\":{\"mscAgencyId\":\"115867\"},\"userId\":null}; OptanonAlertBoxClosed=2020-08-13T03:42:45.080Z; CMSCookieLevel=200; VisitorStatus=11062214903; TS0142aef9=0192b4b6225179b1baa3b4d270b71a4eee782a0192338173beabaa471f306c2a13fe854bf6a7ac08ac21924991864aa7728c54559023beabd273d82285d5f943202adb58da417d61813232e89b240828c090f890c6a74dc4adfec38513d13447be4b5b4404d69f964987b7917f731b858f0c9880a139994b98397c4aeb5bd60b0d0e38ec9e5f3c97b13fb184b4e068506e6086954f8a515f2b7239d2e5c1b9c70f61ca74f736355c58648a6036e9b5d06412389ac41221c5cb740df99c84dc2bfef4a530dbc5e2577c189212eebac723d9ee9f98030f4bc6ca7d824ab313ae5fdd1eaa9886; OptanonConsent=isIABGlobal=false&datestamp=Thu+Aug+13+2020+11%3A43%3A36+GMT%2B0800+(Singapore+Standard+Time)&version=5.9.0&landingPath=NotLandingPage&groups=1%3A1%2C2%3A1%2C3%3A1%2C4%3A1%2C0_53017%3A1%2C0_53020%3A1%2C0_53018%3A1%2C0_53019%3A1%2C101%3A1&AwaitingReconsent=false'\n",
    "#             }\n",
    "#             response = self.session.get(url, headers=headers)\n",
    "#             return response\n",
    "        \n",
    "#         self.response_jsons = []\n",
    "#         first_day = datetime.today().replace(day=1).strftime('%Y-%m-%d')\n",
    "        \n",
    "#         for row in tqdm(self.reduced_df.itertuples(), total=len(self.reduced_df)):\n",
    "#             response_filename = f'MSC {int(row.pol_code)}-{int(row.pod_code)}.json'\n",
    "#             if response_filename not in os.listdir():\n",
    "#                 response = get_schedules(first_day, int(row.pol_code), int(row.pod_code))\n",
    "#                 self.response_jsons.append(response.json())\n",
    "#                 write_json(response.json(), response_filename)\n",
    "#                 time.sleep(random.randint(*self.interval))\n",
    "#             else:\n",
    "#                 with open(response_filename, 'r') as f:\n",
    "#                     self.response_jsons.append(json.load(f))\n",
    "        \n",
    "    def extract(self):\n",
    "        \"\"\"\n",
    "        Extracts information from the JSON responses from the call_api method and assembles the final dataframe.\n",
    "        \"\"\"\n",
    "#         def get_relevant_fields(response, i):\n",
    "#             return {\n",
    "#                 'pol_code': response[0]['Sailings'][i]['PortOfLoadId'],\n",
    "#                 'pod_code': response[0]['Sailings'][i]['PortOfDischargeId'],\n",
    "#                 'Voyage': response[0]['Sailings'][i]['VoyageNum'],\n",
    "#                 'Vessel': response[0]['Sailings'][i]['VesselName'],\n",
    "#                 'updated_etd': response[0]['Sailings'][i]['NextETD'],\n",
    "#                 'updated_eta': response[0]['Sailings'][i]['ArrivalDate']\n",
    "#             }\n",
    "\n",
    "#         self.response_df = pd.DataFrame(([get_relevant_fields(response, i)\n",
    "#                                      for response in self.response_jsons\n",
    "#                                      for i in range(len(response[0]['Sailings']))\n",
    "#                                      if len(response)\n",
    "#                                     ]))\n",
    "        \n",
    "#         # Create reverse mapping from port_code to name\n",
    "#         msc_port_id_reversed = {v:k for k,v in self.msc_port_id.items()}\n",
    "\n",
    "#         # Add additional columns to response_df\n",
    "#         self.response_df['pol_name'] = self.response_df.pol_code.map(msc_port_id_reversed)\n",
    "#         self.response_df['pod_name'] = self.response_df.pod_code.map(msc_port_id_reversed)\n",
    "\n",
    "#         # Merge results back to original dataframe\n",
    "#         merge_key = ['pol_name', 'pod_name', 'Vessel', 'Voyage']\n",
    "#         self.delay_sheet = (self.delay_sheet.reset_index().\n",
    "#                             merge(self.response_df[merge_key + ['updated_eta', 'updated_etd']],\n",
    "#                                   on=merge_key, how='left')\n",
    "#                             .set_index('index')\n",
    "#                             .copy())\n",
    "#         self.delay_sheet.updated_eta = pd.to_datetime(self.delay_sheet.updated_eta.str[:10])\n",
    "#         self.delay_sheet.updated_etd = pd.to_datetime(self.delay_sheet.updated_etd.str[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSCExtractor\n",
    "Currently, there are 2 main Web APIs which we can use for data extraction. These are:\n",
    "1. MSC Search Schedules API\n",
    "    - countryID API\n",
    "2. MSC Arrival-Departure API\n",
    "\n",
    "The Search Schedules API is forward looking and is the preferred mode of extraction. We will extract information for all lines for this first. If the information extraction fails, we will than treat the line as having a vessel that has already left port. We then use the Arrival-Departure API to extract the information for these.\n",
    "\n",
    "The countryID API is a sub-API used jointly with the Search Schedules API, which we will need to query before using the Search Schedules API because the parameters for the Search Schedules API uses numbers instead of the UNLOCODEs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To-do\n",
    "1. Now I just need to figure out how to get the first cookie and use it in subsequent headers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSC Arrival-Departure API\n",
    "Not currently in use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def json_payload(port_of_loading):\n",
    "#     return {\n",
    "#         'mscCode': port_of_loading,\n",
    "#         'isCountry': False\n",
    "#     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = \"https://www.msc.com/Site/WebServices/RouteFinder.svc/PortActivity\"\n",
    "# payload = {\n",
    "#     'mscCode': 'NZBLU',\n",
    "#     'isCountry': False\n",
    "# }\n",
    "# headers = {\n",
    "#     'Accept': '*/*',\n",
    "#     'X-Requested-With': 'XMLHttpRequest',\n",
    "#     'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/84.0.4147.125 Safari/537.36',\n",
    "#     'Content-Type': 'application/json; charset=UTF-8',\n",
    "#     'Origin': 'https://www.msc.com',\n",
    "#     'Sec-Fetch-Site': 'same-origin',\n",
    "#     'Sec-Fetch-Mode': 'cors',\n",
    "#     'Sec-Fetch-Dest': 'empty',\n",
    "#     'Referer': 'https://www.msc.com/arrivals-departures',\n",
    "#     'Accept-Encoding': 'gzip, deflate, br',\n",
    "#     'Accept-Language': 'en-GB,en;q=0.9',\n",
    "#     'Cookie': 'CMSPreferredCulture=en-GB; ASP.NET_SessionId=tht5lkut0asln2goiskoagfe; UrlReferrer=https://www.google.com/; CurrentContact=8b0b2fea-705b-4a4f-b8bf-bb1cd6c982bc; CMSLandingPageLoaded=true; MSCAgencyId=115867; BIGipServerkentico.app~kentico_pool=439883018.20480.0000; _ga=GA1.2.1736073830.1597290148; _gid=GA1.2.1289141279.1597290148; _gcl_au=1.1.345060449.1597290148; __hstc=100935006.13bb76c8a78a8d0a203a993ffef3a3f6.1597290148282.1597290148282.1597290148282.1; __hssrc=1; hubspotutk=13bb76c8a78a8d0a203a993ffef3a3f6; _ym_uid=15972901491036911544; _ym_d=1597290149; _ym_isad=1; _ym_visorc_65601397=w; newsletter-signup-cookie=temp-hidden; _hjid=3e183004-f562-4048-8b60-daccdf9c187c; _hjUserAttributesHash=2c3b62a0e1cd48bdfd4d01b922060e19; _hjCachedUserAttributes={`\"attributes`\":{`\"mscAgencyId`\":`\"115867`\"},`\"userId`\":null}; OptanonAlertBoxClosed=2020-08-13T03:42:45.080Z; CMSCookieLevel=200; VisitorStatus=11062214903; CMSUserPage={`\"TimeStamp`\":`\"2020-08-13T05:43:28.7403678+02:00`\",`\"LastPageDocumentID`\":2969,`\"LastPageNodeID`\":6383,`\"Identifier`\":`\"93e5bd8e-a77a-49db-b00e-1e3712608ca2`\"}; TS0142aef9=0192b4b6225179b1baa3b4d270b71a4eee782a0192338173beabaa471f306c2a13fe854bf6a7ac08ac21924991864aa7728c54559023beabd273d82285d5f943202adb58da417d61813232e89b240828c090f890c6a74dc4adfec38513d13447be4b5b4404d69f964987b7917f731b858f0c9880a139994b98397c4aeb5bd60b0d0e38ec9e5f3c97b13fb184b4e068506e6086954f8a515f2b7239d2e5c1b9c70f61ca74f736355c58648a6036e9b5d06412389ac41221c5cb740df99c84dc2bfef4a530dbc5e2577c189212eebac723d9ee9f98030f4bc6ca7d824ab313ae5fdd1eaa9886; OptanonConsent=isIABGlobal=false&datestamp=Thu+Aug+13+2020+11%3A43%3A36+GMT%2B0800+(Singapore+Standard+Time)&version=5.9.0&landingPath=NotLandingPage&groups=1%3A1%2C2%3A1%2C3%3A1%2C4%3A1%2C0_53017%3A1%2C0_53020%3A1%2C0_53018%3A1%2C0_53019%3A1%2C101%3A1&AwaitingReconsent=false; _gat=1; _gat_local=1; __hssc=100935006.3.1597290148283; _gali=ui-id-2'\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# response = session.request(\"POST\", url, headers=headers, json=payload)\n",
    "# response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSCExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../..')\n",
    "# Delay report skeleton\n",
    "delay_report = DelayReport()\n",
    "delay_report.run_bs()\n",
    "delay_report.run_msc()\n",
    "delay_report.run_g2()\n",
    "delay_report.calculate_deltas()\n",
    "delay_report.output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MSCExtractor:\n",
    "    \"\"\"\n",
    "    Extracts information from the MSC Portal.\n",
    "    \n",
    "    Methods\n",
    "    -------\n",
    "    get_countryID:\n",
    "        Gets the countryID mappings via the CountryID API in order to use the Search Schedules API.\n",
    "        \n",
    "    prepare:\n",
    "        A single query to the Search Schedules API can provide information to multiple lines on the delay_sheet.\n",
    "        Further filters self.delay_sheet to a smaller list of searches needed to fulfill all the lines on the\n",
    "            delay_sheet. This reduces the total number of calls made to the Search Schedules API and prevents\n",
    "            duplication of API calls.\n",
    "        \n",
    "    call_api:\n",
    "        Makes calls to the Search Schedules API, using information from the prepare method as parameters in the\n",
    "        API request. Also saves the API responses into a subdirectory \"responses/<today_date>\".\n",
    "    \n",
    "    extract:\n",
    "        Extracts information from the JSON responses from the call_api method and assembles the final dataframe.\n",
    "    \"\"\"\n",
    "    def __init__(self, main_delay_sheet: pd.DataFrame, interval: tuple):\n",
    "        # Get the MSC delay sheet\n",
    "        self.delay_sheet = (main_delay_sheet.loc[main_delay_sheet['Fwd Agent'] == 'MSC']\n",
    "                            .drop(['updated_etd', 'updated_eta', 'No. of days delayed ETD',\n",
    "                                   'No. of days delayed ETA', 'Reason of Delay'], axis=1)\n",
    "                            .copy())\n",
    "\n",
    "        # Get the MSC-specific port names from the UNLOCODEs\n",
    "        self.port_mapping = {v['Port Code']: v['MSC Port Name'] for k,v in (pd.read_excel('../../data/MSC Port Code Mapping.xlsx')\n",
    "                                                                   .to_dict('index').items())}\n",
    "        \n",
    "        # Get port name\n",
    "        self.delay_sheet = self.delay_sheet.assign(pol_name=lambda x: x['Port of Loading'].apply(lambda y: self.port_mapping.get(y)),\n",
    "                                                   pod_name=lambda x: x['Port of discharge'].apply(lambda y: self.port_mapping.get(y))).copy()\n",
    "\n",
    "        self.interval = interval\n",
    "        self.session = requests.Session()\n",
    "        \n",
    "    def get_countryID(self):\n",
    "        \"\"\"\n",
    "        Checks if the query for countryID has been done today.\n",
    "        If it has been done, skips it and uses the existing countryID JSON file.\n",
    "        Otherwise, queries the countryID API.\n",
    "        \n",
    "        This API call does not require a cookie.\n",
    "        \"\"\"\n",
    "        if 'countryID.json' not in os.listdir():\n",
    "            def query_id(port: str):\n",
    "                url = f\"https://www.msc.com/api/schedules/autocomplete?q={port}\"\n",
    "                return self.session.get(url)\n",
    "\n",
    "            def get_id(response):\n",
    "                if len(response.json()):\n",
    "                    return response.json()[0].get('id')\n",
    "\n",
    "            msc_locations = list(self.delay_sheet.pol_name.unique()) + list(self.delay_sheet.pod_name.unique())\n",
    "            location_code_responses = {location: query_id(location) for location in tqdm(msc_locations)}\n",
    "            self.msc_port_id = {k:get_id(v) for k,v in location_code_responses.items()}\n",
    "            write_json(self.msc_port_id, 'countryID.json')\n",
    "\n",
    "            # PODs with no pod_id\n",
    "            exception_cases = [k for k,v in self.msc_port_id.items() if v is None]\n",
    "            write_json(exception_cases, 'msc_exceptions.txt')\n",
    "        else:\n",
    "            read_config(self, 'msc_port_id', 'countryID.json')\n",
    "\n",
    "    def prepare(self):\n",
    "        \"\"\"\n",
    "        Further filters self.delay_sheet to a smaller list of searches needed to fulfill all the lines on the\n",
    "            delay_sheet. Also maps the UNLOCODE to their respective countryID.\n",
    "        \"\"\"\n",
    "        # Further filter by POL-Vessel-Voyage to get ETD, POD-Vessel-Voyage to get ETA\n",
    "        key = ['pol_name', 'pod_name']\n",
    "        self.reduced_df = self.delay_sheet.drop_duplicates(key)[key].sort_values(key)\n",
    "\n",
    "        self.reduced_df['pol_code'] = self.reduced_df.pol_name.map(self.msc_port_id)\n",
    "        self.reduced_df['pod_code'] = self.reduced_df.pod_name.map(self.msc_port_id)\n",
    "\n",
    "        # Unable to handle those with no pod_id in MSC; dropping these lines\n",
    "        self.reduced_df.dropna(inplace=True)\n",
    "        \n",
    "    def call_api(self):\n",
    "        \"\"\"\n",
    "        Makes calls to the Search Schedules API, using information from the prepare method as parameters in the\n",
    "        API request. Also saves the API responses into a subdirectory \"responses/<today_date>\".\n",
    "        \"\"\"\n",
    "        def get_schedules(etd: str, pol: str, pod: str):\n",
    "            url = f\"https://www.msc.com/api/schedules/search?WeeksOut=8&DirectRoutes=false&Date={etd}&From={pol}&To={pod}\"\n",
    "            headers = {\n",
    "                'Accept': 'application/json',\n",
    "                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/84.0.4147.105 Safari/537.36',\n",
    "                'Content-Type': 'application/json',\n",
    "                'Sec-Fetch-Site': 'same-origin',\n",
    "                'Sec-Fetch-Mode': 'cors',\n",
    "                'Sec-Fetch-Dest': 'empty',\n",
    "                'Referer': 'https://www.msc.com/search-schedules',\n",
    "                'Accept-Language': 'en-GB,en;q=0.9',\n",
    "                'Cookie': 'CMSPreferredCulture=en-GB; ASP.NET_SessionId=tht5lkut0asln2goiskoagfe; UrlReferrer=https://www.google.com/; CurrentContact=8b0b2fea-705b-4a4f-b8bf-bb1cd6c982bc; MSCAgencyId=115867; BIGipServerkentico.app~kentico_pool=439883018.20480.0000; _ga=GA1.2.1736073830.1597290148; _gid=GA1.2.1289141279.1597290148; _gcl_au=1.1.345060449.1597290148; __hstc=100935006.13bb76c8a78a8d0a203a993ffef3a3f6.1597290148282.1597290148282.1597290148282.1; hubspotutk=13bb76c8a78a8d0a203a993ffef3a3f6; __hssrc=1; _ym_uid=15972901491036911544; _ym_d=1597290149; _ym_isad=1; newsletter-signup-cookie=temp-hidden; _hjid=3e183004-f562-4048-8b60-daccdf9c187c; _hjUserAttributesHash=2c3b62a0e1cd48bdfd4d01b922060e19; _hjCachedUserAttributes={\"attributes\":{\"mscAgencyId\":\"115867\"},\"userId\":null}; OptanonAlertBoxClosed=2020-08-13T03:42:45.080Z; CMSCookieLevel=200; VisitorStatus=11062214903; TS0142aef9=0192b4b6225179b1baa3b4d270b71a4eee782a0192338173beabaa471f306c2a13fe854bf6a7ac08ac21924991864aa7728c54559023beabd273d82285d5f943202adb58da417d61813232e89b240828c090f890c6a74dc4adfec38513d13447be4b5b4404d69f964987b7917f731b858f0c9880a139994b98397c4aeb5bd60b0d0e38ec9e5f3c97b13fb184b4e068506e6086954f8a515f2b7239d2e5c1b9c70f61ca74f736355c58648a6036e9b5d06412389ac41221c5cb740df99c84dc2bfef4a530dbc5e2577c189212eebac723d9ee9f98030f4bc6ca7d824ab313ae5fdd1eaa9886; OptanonConsent=isIABGlobal=false&datestamp=Thu+Aug+13+2020+11%3A43%3A36+GMT%2B0800+(Singapore+Standard+Time)&version=5.9.0&landingPath=NotLandingPage&groups=1%3A1%2C2%3A1%2C3%3A1%2C4%3A1%2C0_53017%3A1%2C0_53020%3A1%2C0_53018%3A1%2C0_53019%3A1%2C101%3A1&AwaitingReconsent=false'\n",
    "            }\n",
    "            response = self.session.get(url, headers=headers)\n",
    "            return response\n",
    "        \n",
    "        self.response_jsons = []\n",
    "        first_day = datetime.today().replace(day=1).strftime('%Y-%m-%d')\n",
    "        \n",
    "        for row in tqdm(self.reduced_df.itertuples(), total=len(self.reduced_df)):\n",
    "            response_filename = f'MSC {int(row.pol_code)}-{int(row.pod_code)}.json'\n",
    "            if response_filename not in os.listdir():\n",
    "                response = get_schedules(first_day, int(row.pol_code), int(row.pod_code))\n",
    "                self.response_jsons.append(response.json())\n",
    "                write_json(response.json(), response_filename)\n",
    "                time.sleep(random.randint(*self.interval))\n",
    "            else:\n",
    "                with open(response_filename, 'r') as f:\n",
    "                    self.response_jsons.append(json.load(f))\n",
    "        \n",
    "        \n",
    "    def extract(self):\n",
    "        \"\"\"\n",
    "        Extracts information from the JSON responses from the call_api method and assembles the final dataframe.\n",
    "        \"\"\"\n",
    "        def get_relevant_fields(response, i):\n",
    "            return {\n",
    "                'pol_code': response[0]['Sailings'][i]['PortOfLoadId'],\n",
    "                'pod_code': response[0]['Sailings'][i]['PortOfDischargeId'],\n",
    "                'Voyage': response[0]['Sailings'][i]['VoyageNum'],\n",
    "                'Vessel': response[0]['Sailings'][i]['VesselName'],\n",
    "                'updated_etd': response[0]['Sailings'][i]['NextETD'],\n",
    "                'updated_eta': response[0]['Sailings'][i]['ArrivalDate']\n",
    "            }\n",
    "\n",
    "        self.response_df = pd.DataFrame(([get_relevant_fields(response, i)\n",
    "                                     for response in self.response_jsons\n",
    "                                     for i in range(len(response[0]['Sailings']))\n",
    "                                     if len(response)\n",
    "                                    ]))\n",
    "        \n",
    "        # Create reverse mapping from port_code to name\n",
    "        msc_port_id_reversed = {v:k for k,v in self.msc_port_id.items()}\n",
    "\n",
    "        # Add additional columns to response_df\n",
    "        self.response_df['pol_name'] = self.response_df.pol_code.map(msc_port_id_reversed)\n",
    "        self.response_df['pod_name'] = self.response_df.pod_code.map(msc_port_id_reversed)\n",
    "\n",
    "        # Merge results back to original dataframe\n",
    "        merge_key = ['pol_name', 'pod_name', 'Vessel', 'Voyage']\n",
    "        self.delay_sheet = (self.delay_sheet.reset_index().\n",
    "                            merge(self.response_df[merge_key + ['updated_eta', 'updated_etd']],\n",
    "                                  on=merge_key, how='left')\n",
    "                            .set_index('index')\n",
    "                            .copy())\n",
    "        self.delay_sheet.updated_eta = pd.to_datetime(self.delay_sheet.updated_eta.str[:10])\n",
    "        self.delay_sheet.updated_etd = pd.to_datetime(self.delay_sheet.updated_etd.str[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class G2Extractor:\n",
    "    \"\"\"\n",
    "    Extracts information from the G2 Schedule Excel file by using pd.apply to the delay_sheet.\n",
    "    \n",
    "    Methods\n",
    "    -------\n",
    "    extract:\n",
    "        Extracts data from the Excel dataframe, using two helper methods get_updated_eta and get_updated_etd.\n",
    "    \n",
    "    get_updated_eta, get_updated_etd:\n",
    "        Helper methods to extract the updated_eta and updated_etd given a row in the delay_sheet.\n",
    "    \"\"\"\n",
    "    def __init__(self, g2_file: str, main_delay_sheet: pd.DataFrame):\n",
    "        self.schedule = pd.read_excel(\n",
    "            Path('../../' + g2_file), skiprows=9, index_col='Unnamed: 0')\n",
    "        self.delay_sheet = main_delay_sheet.query(f\"`Fwd Agent` in {['G2OCEAN']}\").copy()\n",
    "        self.port_mapping = {v['Port Code']: v['G2 Port Name'] for k,v in (pd.read_excel('../../data/G2 Port Code Mapping.xlsx')\n",
    "                                                           .to_dict('index').items())}\n",
    "\n",
    "    def get_updated_etd(self, row):\n",
    "        try:\n",
    "            # column_index_etd is the column number that points to the ETD\n",
    "            column_index_etd = np.argwhere(\n",
    "                self.schedule.columns.str.contains(row['Vessel']))[0][0] + 1\n",
    "        except IndexError:\n",
    "            return np.nan\n",
    "        return self.schedule.loc[self.schedule.index == self.port_mapping.get(row['Port of Loading'])].iloc[:, column_index_etd][0]\n",
    "\n",
    "    def get_updated_eta(self, row):\n",
    "        try:\n",
    "            # column_index_eta is the column number that points to the ETA\n",
    "            column_index_eta = np.argwhere(\n",
    "                self.schedule.columns.str.contains(row['Vessel']))[0][0]\n",
    "        except IndexError:\n",
    "            return np.nan\n",
    "        return self.schedule.loc[self.schedule.index == self.port_mapping.get(row['Port of discharge'])].iloc[:, column_index_eta][0]\n",
    "\n",
    "    def extract(self):\n",
    "        \"\"\"\n",
    "        Extracts data from the Excel dataframe, using two helper methods get_updated_eta and get_updated_etd.\n",
    "        \"\"\"\n",
    "        self.delay_sheet['updated_etd'] = self.delay_sheet.apply(self.get_updated_etd, axis=1)\n",
    "        self.delay_sheet['updated_eta'] = self.delay_sheet.apply(self.get_updated_eta, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DelayReport:\n",
    "    \"\"\"\n",
    "    Main delay report class that loads configurations that are shared across Extractors and runs the Extractors.\n",
    "    \n",
    "    Methods\n",
    "    -------\n",
    "    run_bs, run_msc, run_g2:\n",
    "        Runs the corresponding extraction by instantiating a relevant Extractor class.\n",
    "        \n",
    "    calculate_deltas:\n",
    "        Calculates the deltas from the updated delay_sheet.\n",
    "        \n",
    "    output:\n",
    "        Write the final delay report Excel file to disk.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        # Read configurations\n",
    "        read_config(self, 'config', 'data/config.json')\n",
    "        \n",
    "        # Used to map carrier names to the ones BigSchedules uses and supports\n",
    "        read_config(self, 'carrier_mapping', 'data/carrier_mapping.json')\n",
    "\n",
    "        # Random interval in seconds\n",
    "        self.interval = (self.config.get('randomiser_lower_interval'), self.config.get('randomiser_upper_interval'))\n",
    "\n",
    "        # Prepare UNLOCODE to port name mapping\n",
    "        self.port_mapping = (\n",
    "            pd.concat([pd.read_csv(p, usecols=[1, 2, 4, 5], engine='python', names=[\n",
    "                      'country', 'port', 'name', 'subdiv']) for p in Path('data').glob(\"*UNLOCODE CodeListPart*\")])\n",
    "            .query('port == port')\n",
    "            .assign(uncode=lambda x: x.country.str.cat(x.port),\n",
    "                    full_name=lambda x: np.where(x.subdiv.notnull(), x.name.str.cat(x.subdiv, sep=\", \"), x.name))\n",
    "            .drop_duplicates('uncode')\n",
    "            .set_index('uncode')\n",
    "            .to_dict('index'))\n",
    "        \n",
    "        # Read the vessel delay tracking file\n",
    "        self.xl = pd.ExcelFile(self.config['delay_filename'])\n",
    "        # today_date = datetime.now().strftime('%d.%m.%Y')\n",
    "        # if today_date not in self.xl.sheet_names:\n",
    "        #     raise Exception(\n",
    "        #         f\"The script cannot find today's date ({today_date}) in the Vessel Delay Tracking.xlsx file provided. Please check that the sheets are correctly named - the script will only operate on a sheet with today's date.\")\n",
    "\n",
    "        # Assemble the final dataframe to update\n",
    "        self.main_delay_sheet = self.xl.parse(pd.to_datetime(self.xl.sheet_names,\n",
    "                                                             errors='coerce',\n",
    "                                                             format='%d.%m.%Y').max().date().strftime('%d.%m.%Y'),\n",
    "                                              parse_dates=True).copy()\n",
    "        \n",
    "        # If our current Excel file already has an updated_eta or updated_etd columns, we drop them\n",
    "        new_columns = ['updated_etd', 'updated_eta', 'No. of days delayed ETD', 'No. of days delayed ETA', 'Reason of Delay']\n",
    "        for updated_column in new_columns:\n",
    "            if updated_column in self.main_delay_sheet.columns:\n",
    "                self.main_delay_sheet.drop(updated_column, axis=1, inplace=True)\n",
    "        \n",
    "        # Add new columns to the right side of the dataframe\n",
    "        self.main_delay_sheet[new_columns] = pd.DataFrame([[pd.NaT for i in range(4)] + [np.nan]])\n",
    "        \n",
    "        # Today's directory\n",
    "        today_path = Path('responses/' + datetime.now().strftime('%Y-%m-%d'))\n",
    "        try:\n",
    "            os.makedirs(today_path)\n",
    "        except FileExistsError:\n",
    "            pass\n",
    "        os.chdir(today_path)\n",
    "        \n",
    "    def run_bs(self):\n",
    "        if self.config.get('run_bs'):\n",
    "            bs_extractor = BSExtractor(self.main_delay_sheet, self.interval)\n",
    "            bs_extractor.extract()\n",
    "        \n",
    "    def run_msc(self):\n",
    "        if self.config.get('run_msc'):\n",
    "            self.msc_extractor = MSCExtractor(self.main_delay_sheet, self.interval)\n",
    "            self.msc_extractor.get_countryID()\n",
    "            self.msc_extractor.prepare()\n",
    "            self.msc_extractor.call_api()\n",
    "            self.msc_extractor.extract()\n",
    "    \n",
    "    def run_g2(self):\n",
    "        if self.config.get('run_g2'):\n",
    "            self.g2_extractor = G2Extractor(self.config.get('g2_filename'), self.main_delay_sheet)\n",
    "            self.g2_extractor.extract()\n",
    "\n",
    "    def calculate_deltas(self):\n",
    "        # Update the dataframe\n",
    "        if self.config.get('run_bs'):\n",
    "            self.main_delay_sheet.update(self.bs_extractor.delay_sheet)\n",
    "\n",
    "        if self.config.get('run_msc'):\n",
    "            self.main_delay_sheet.update(self.msc_extractor.delay_sheet)\n",
    "            \n",
    "        if self.config.get('run_g2'):\n",
    "            self.main_delay_sheet.update(self.g2_extractor.delay_sheet)\n",
    "\n",
    "        # Calculate the deltas\n",
    "        self.main_delay_sheet['No. of days delayed ETD'] = (self.main_delay_sheet.updated_etd\n",
    "                                                            - pd.to_datetime(self.main_delay_sheet['ETD Date'])).dt.days\n",
    "        self.main_delay_sheet['No. of days delayed ETA'] = (self.main_delay_sheet.updated_eta\n",
    "                                                            - pd.to_datetime(self.main_delay_sheet['Disport ETA'])).dt.days\n",
    "\n",
    "        # Format the dates correctly via strftime\n",
    "        date_columns = ['ETD Date', 'Disport ETA', 'updated_etd', 'updated_eta']\n",
    "        for column in date_columns:\n",
    "            self.main_delay_sheet[column] = self.main_delay_sheet[column].dt.strftime('%d/%m/%Y')\n",
    "    \n",
    "    def output(self):\n",
    "        # Output the excel file\n",
    "        saved_file = f\"Vessel Delay Tracking - {datetime.today().strftime('%d.%m.%Y')}.xlsx\"\n",
    "        self.main_delay_sheet.to_excel(Path('../../' + saved_file), index=False)\n",
    "        os.startfile(Path('../../' + saved_file))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
