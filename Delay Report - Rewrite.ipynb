{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import logging\n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "\n",
    "from pathlib import Path\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "# pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read configuration file\n",
    "with open(\"data/config.json\", \"r\") as f:\n",
    "    config = json.load(f)\n",
    "    \n",
    "# Used to map carrier names to the ones BigSchedule uses and supports\n",
    "with open(\"data/carrier_mapping.json\", \"r\") as f:\n",
    "    carrier_mapping = json.load(f)\n",
    "\n",
    "# Bigschedule login\n",
    "with open(\"data/bigschedules_login.json\", \"r\") as f:\n",
    "    bs_login = json.load(f)\n",
    "    \n",
    "# Prepare base information\n",
    "# UNLOCODE to port name mapping\n",
    "port_mapping = (\n",
    "    pd.concat([pd.read_csv(p, usecols=[1, 2, 4, 5], engine='python', names=[\n",
    "              'country', 'port', 'name', 'subdiv']) for p in Path('data').glob(\"*UNLOCODE CodeListPart*\")])\n",
    "    .query('port == port')\n",
    "    .assign(\n",
    "        uncode=lambda x: x.country.str.cat(x.port),\n",
    "        full_name=lambda x: np.where(\n",
    "            x.subdiv.notnull(), x.name.str.cat(x.subdiv, sep=\", \"), x.name)\n",
    "    )\n",
    "    .drop_duplicates('uncode')\n",
    "    .set_index('uncode')\n",
    "    .to_dict('index')\n",
    ")\n",
    "\n",
    "# Read the vessel delay tracking file\n",
    "xl = pd.ExcelFile('Vessel Delay Tracking.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BSExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigschedules_sheet = (\n",
    "    xl.parse(pd.to_datetime(xl.sheet_names,\n",
    "                            errors='coerce',\n",
    "                            format='%d.%m.%Y').max().date().strftime('%d.%m.%Y'),\n",
    "                            parse_dates=True)\n",
    "                            .query(f\"`Fwd Agent` in {[k for k,v in carrier_mapping.items() if v != '']}\")\n",
    "                            .replace({'Fwd Agent': carrier_mapping})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get port name\n",
    "bigschedules_sheet = bigschedules_sheet.assign(\n",
    "    pol_name=lambda x: x['Port of Loading'].apply(\n",
    "        lambda y: port_mapping.get(y)['name']),\n",
    "    pod_name=lambda x: x['Port of discharge'].apply(\n",
    "        lambda y: port_mapping.get(y)['name']),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine what searches need to be made (splitting of concerns amongst BigSchedules, MSC & G2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the searches on the BigSchedules portal\n",
    "'''\n",
    "Takes in a list of dataframe of vessels, their carriers, POL, POD.\n",
    "Shrinks the above dataframe to vessels & their carriers. Uses this new dataframe for querying BigSchedules.\n",
    "Outputs an updated dataframe of vessels & their carriers with 2 additional columns updated_eta and updated_etd.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSCExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the MSC delay sheet\n",
    "msc_delay_sheet = (xl.parse(pd.to_datetime(xl.sheet_names,\n",
    "                            errors='coerce',\n",
    "                            format='%d.%m.%Y').max().date().strftime('%d.%m.%Y'),\n",
    "                            parse_dates=True)\n",
    "                            .query(f\"`Fwd Agent` in {['MSC']}\")\n",
    "                            .replace({'Fwd Agent': carrier_mapping})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msc_delay_sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msc_delay_sheet.drop_duplicates('Port of Loading')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Further filter by POL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = requests.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I just need to figure out how to get the first cookie and use it in subsequent headers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_payload(port_of_loading):\n",
    "    return {\n",
    "        'mscCode': port_of_loading,\n",
    "        'isCountry': False\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSC Arrival-Departure API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.msc.com/Site/WebServices/RouteFinder.svc/PortActivity\"\n",
    "payload = {\n",
    "    'mscCode': 'NZBLU',\n",
    "    'isCountry': False\n",
    "}\n",
    "headers = {\n",
    "    'Accept': '*/*',\n",
    "    'X-Requested-With': 'XMLHttpRequest',\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/84.0.4147.125 Safari/537.36',\n",
    "    'Content-Type': 'application/json; charset=UTF-8',\n",
    "    'Origin': 'https://www.msc.com',\n",
    "    'Sec-Fetch-Site': 'same-origin',\n",
    "    'Sec-Fetch-Mode': 'cors',\n",
    "    'Sec-Fetch-Dest': 'empty',\n",
    "    'Referer': 'https://www.msc.com/arrivals-departures',\n",
    "    'Accept-Encoding': 'gzip, deflate, br',\n",
    "    'Accept-Language': 'en-GB,en;q=0.9',\n",
    "    'Cookie': 'CMSPreferredCulture=en-GB; ASP.NET_SessionId=tht5lkut0asln2goiskoagfe; UrlReferrer=https://www.google.com/; CurrentContact=8b0b2fea-705b-4a4f-b8bf-bb1cd6c982bc; CMSLandingPageLoaded=true; MSCAgencyId=115867; BIGipServerkentico.app~kentico_pool=439883018.20480.0000; _ga=GA1.2.1736073830.1597290148; _gid=GA1.2.1289141279.1597290148; _gcl_au=1.1.345060449.1597290148; __hstc=100935006.13bb76c8a78a8d0a203a993ffef3a3f6.1597290148282.1597290148282.1597290148282.1; __hssrc=1; hubspotutk=13bb76c8a78a8d0a203a993ffef3a3f6; _ym_uid=15972901491036911544; _ym_d=1597290149; _ym_isad=1; _ym_visorc_65601397=w; newsletter-signup-cookie=temp-hidden; _hjid=3e183004-f562-4048-8b60-daccdf9c187c; _hjUserAttributesHash=2c3b62a0e1cd48bdfd4d01b922060e19; _hjCachedUserAttributes={`\"attributes`\":{`\"mscAgencyId`\":`\"115867`\"},`\"userId`\":null}; OptanonAlertBoxClosed=2020-08-13T03:42:45.080Z; CMSCookieLevel=200; VisitorStatus=11062214903; CMSUserPage={`\"TimeStamp`\":`\"2020-08-13T05:43:28.7403678+02:00`\",`\"LastPageDocumentID`\":2969,`\"LastPageNodeID`\":6383,`\"Identifier`\":`\"93e5bd8e-a77a-49db-b00e-1e3712608ca2`\"}; TS0142aef9=0192b4b6225179b1baa3b4d270b71a4eee782a0192338173beabaa471f306c2a13fe854bf6a7ac08ac21924991864aa7728c54559023beabd273d82285d5f943202adb58da417d61813232e89b240828c090f890c6a74dc4adfec38513d13447be4b5b4404d69f964987b7917f731b858f0c9880a139994b98397c4aeb5bd60b0d0e38ec9e5f3c97b13fb184b4e068506e6086954f8a515f2b7239d2e5c1b9c70f61ca74f736355c58648a6036e9b5d06412389ac41221c5cb740df99c84dc2bfef4a530dbc5e2577c189212eebac723d9ee9f98030f4bc6ca7d824ab313ae5fdd1eaa9886; OptanonConsent=isIABGlobal=false&datestamp=Thu+Aug+13+2020+11%3A43%3A36+GMT%2B0800+(Singapore+Standard+Time)&version=5.9.0&landingPath=NotLandingPage&groups=1%3A1%2C2%3A1%2C3%3A1%2C4%3A1%2C0_53017%3A1%2C0_53020%3A1%2C0_53018%3A1%2C0_53019%3A1%2C101%3A1&AwaitingReconsent=false; _gat=1; _gat_local=1; __hssc=100935006.3.1597290148283; _gali=ui-id-2'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = session.request(\"POST\", url, headers=headers, json=payload)\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(session.cookies.get_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSC Search Schedules API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need the PortOfLoadId and PortOfDischargeID for every port.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.msc.com/api/schedules/search?WeeksOut=8&DirectRoutes=false&Date=2020-08-11&From=1034&To=221\"\n",
    "headers = {\n",
    "  'Accept': 'application/json',\n",
    "  'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/84.0.4147.105 Safari/537.36',\n",
    "  'Content-Type': 'application/json',\n",
    "  'Sec-Fetch-Site': 'same-origin',\n",
    "  'Sec-Fetch-Mode': 'cors',\n",
    "  'Sec-Fetch-Dest': 'empty',\n",
    "  'Referer': 'https://www.msc.com/search-schedules',\n",
    "  'Accept-Language': 'en-GB,en;q=0.9',\n",
    "  'Cookie': 'CMSPreferredCulture=en-GB; ASP.NET_SessionId=tht5lkut0asln2goiskoagfe; UrlReferrer=https://www.google.com/; CurrentContact=8b0b2fea-705b-4a4f-b8bf-bb1cd6c982bc; MSCAgencyId=115867; BIGipServerkentico.app~kentico_pool=439883018.20480.0000; _ga=GA1.2.1736073830.1597290148; _gid=GA1.2.1289141279.1597290148; _gcl_au=1.1.345060449.1597290148; __hstc=100935006.13bb76c8a78a8d0a203a993ffef3a3f6.1597290148282.1597290148282.1597290148282.1; hubspotutk=13bb76c8a78a8d0a203a993ffef3a3f6; __hssrc=1; _ym_uid=15972901491036911544; _ym_d=1597290149; _ym_isad=1; newsletter-signup-cookie=temp-hidden; _hjid=3e183004-f562-4048-8b60-daccdf9c187c; _hjUserAttributesHash=2c3b62a0e1cd48bdfd4d01b922060e19; _hjCachedUserAttributes={\"attributes\":{\"mscAgencyId\":\"115867\"},\"userId\":null}; OptanonAlertBoxClosed=2020-08-13T03:42:45.080Z; CMSCookieLevel=200; VisitorStatus=11062214903; TS0142aef9=0192b4b6225179b1baa3b4d270b71a4eee782a0192338173beabaa471f306c2a13fe854bf6a7ac08ac21924991864aa7728c54559023beabd273d82285d5f943202adb58da417d61813232e89b240828c090f890c6a74dc4adfec38513d13447be4b5b4404d69f964987b7917f731b858f0c9880a139994b98397c4aeb5bd60b0d0e38ec9e5f3c97b13fb184b4e068506e6086954f8a515f2b7239d2e5c1b9c70f61ca74f736355c58648a6036e9b5d06412389ac41221c5cb740df99c84dc2bfef4a530dbc5e2577c189212eebac723d9ee9f98030f4bc6ca7d824ab313ae5fdd1eaa9886; OptanonConsent=isIABGlobal=false&datestamp=Thu+Aug+13+2020+11%3A43%3A36+GMT%2B0800+(Singapore+Standard+Time)&version=5.9.0&landingPath=NotLandingPage&groups=1%3A1%2C2%3A1%2C3%3A1%2C4%3A1%2C0_53017%3A1%2C0_53020%3A1%2C0_53018%3A1%2C0_53019%3A1%2C101%3A1&AwaitingReconsent=false'\n",
    "}\n",
    "\n",
    "response = session.request(\"GET\", url, headers=headers)\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "response.json()[0]['Sailings'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(response.json()[0]['Sailings'])):\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSC countryID API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### G2Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class G2Extractor:\n",
    "    def __init__(self, g2_file, xl, carrier_mapping):\n",
    "        self.schedule = pd.read_excel(g2_file, skiprows=9, index_col='Unnamed: 0')\n",
    "        self.delay_sheet = (xl.parse(pd.to_datetime(xl.sheet_names,\n",
    "                                errors='coerce',\n",
    "                                format='%d.%m.%Y').max().date().strftime('%d.%m.%Y'),\n",
    "                                parse_dates=True)\n",
    "                                .query(f\"`Fwd Agent` in {['G2OCEAN']}\")\n",
    "                                .replace({'Fwd Agent': carrier_mapping}))\n",
    "        self.g2_port_map = {\n",
    "            'AUPTJ': 'Portland',\n",
    "            'AUNTL': 'Newcastle',\n",
    "            'AUGLT': 'Gladstone',\n",
    "            'NZTWI': 'Bluff',\n",
    "            'TWKHH': 'Kaohsiung',\n",
    "            'KRINC': 'Inchon',\n",
    "            'KRPUS': 'Busan',\n",
    "            'JPYOK': 'Yokohama',\n",
    "            'JPNGO': 'Nagoya',\n",
    "            'JPOSA': 'Osaka',\n",
    "            'JPTOY': 'Toyama',\n",
    "            'JPIHA': 'Niihama',\n",
    "            'HKHKG': 'Hong Kong',\n",
    "            'CNSHA': 'Shanghai'\n",
    "        }\n",
    "        \n",
    "    def get_updated_etd(self, row):\n",
    "        try:\n",
    "            # column_index_etd is the column number that points to the ETD\n",
    "            column_index_etd = np.argwhere(self.schedule.columns.str.contains(row['Vessel']))[0][0] + 1\n",
    "        except IndexError:\n",
    "            return np.nan\n",
    "        return self.schedule.loc[self.schedule.index == self.g2_port_map.get(row['Port of Loading'])].iloc[:, column_index_etd][0] \n",
    "    \n",
    "    def get_updated_eta(self, row):\n",
    "        try:\n",
    "            # column_index_eta is the column number that points to the ETA\n",
    "            column_index_eta = np.argwhere(self.schedule.columns.str.contains(row['Vessel']))[0][0]\n",
    "        except IndexError:\n",
    "            return np.nan\n",
    "        return self.schedule.loc[self.schedule.index == self.g2_port_map.get(row['Port of discharge'])].iloc[:, column_index_eta][0]\n",
    "    \n",
    "    def extract(self):\n",
    "        self.delay_sheet['updated_etd'] = self.delay_sheet.apply(self.get_updated_etd, axis=1)\n",
    "        self.delay_sheet['updated_eta'] = self.delay_sheet.apply(self.get_updated_eta, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DelayReport:\n",
    "    def __init__(self):\n",
    "        # Read configuration file\n",
    "        with open(\"data/config.json\", \"r\") as f:\n",
    "            self.config = json.load(f)\n",
    "            \n",
    "        # Used to map carrier names to the ones BigSchedules uses and supports\n",
    "        with open(\"data/carrier_mapping.json\", \"r\") as f:\n",
    "            self.carrier_mapping = json.load(f)\n",
    "        \n",
    "        # BigSchedules login\n",
    "        with open(\"data/bigschedules_login.json\", \"r\") as f:\n",
    "            self.bs_login = json.load(f)\n",
    "        \n",
    "        # Prepare base information\n",
    "        # UNLOCODE to port name mapping\n",
    "        self.port_mapping = (\n",
    "            pd.concat([pd.read_csv(p, usecols=[1, 2, 4, 5], engine='python', names=[\n",
    "                      'country', 'port', 'name', 'subdiv']) for p in Path('data').glob(\"*UNLOCODE CodeListPart*\")])\n",
    "            .query('port == port')\n",
    "            .assign(uncode=lambda x: x.country.str.cat(x.port),\n",
    "                    full_name=lambda x: np.where(x.subdiv.notnull(), x.name.str.cat(x.subdiv, sep=\", \"), x.name))\n",
    "            .drop_duplicates('uncode')\n",
    "            .set_index('uncode')\n",
    "            .to_dict('index'))\n",
    "        \n",
    "        # Read the vessel delay tracking file\n",
    "        self.xl = pd.ExcelFile('Vessel Delay Tracking.xlsx')\n",
    "        # today_date = datetime.now().strftime('%d.%m.%Y')\n",
    "        # if today_date not in self.xl.sheet_names:\n",
    "        #     raise Exception(\n",
    "        #         f\"The script cannot find today's date ({today_date}) in the Vessel Delay Tracking.xlsx file provided. Please check that the sheets are correctly named - the script will only operate on a sheet with today's date.\")\n",
    "        \n",
    "    def run_bs(self):\n",
    "        if self.config.get('run_bs'):\n",
    "            bs_extractor = BSExtractor()\n",
    "            bs_extractor.extract()\n",
    "        \n",
    "    def run_msc(self):\n",
    "        if self.config.get('run_msc'):\n",
    "            self.msc_extractor = MSCExtractor(self.xl, self.carrier_mapping)\n",
    "            self.msc_extractor.extract()\n",
    "    \n",
    "    def run_g2(self):\n",
    "        if self.config.get('run_g2'):\n",
    "            self.g2_extractor = G2Extractor(self.config.get('g2_filename'), self.xl, self.carrier_mapping)\n",
    "            self.g2_extractor.extract()\n",
    "    \n",
    "    def assemble(self):\n",
    "        # Assemble the final dataframe to update\n",
    "        main_delay_sheet = self.xl.parse()\n",
    "\n",
    "        # Add new columns to the right side of the dataframe\n",
    "        new_columns = ['updated_etd', 'updated_eta', 'No. of days delayed ETD', 'No. of days delayed ETA', 'Reason of Delay']\n",
    "        main_delay_sheet[new_columns] = pd.DataFrame([[pd.NaT for i in range(4)] + [np.nan]])\n",
    "\n",
    "        if self.config.get('run_bs'):\n",
    "            main_delay_sheet.update(self.bs_extractor.delay_sheet)\n",
    "        \n",
    "        if self.config.get('run_msc'):\n",
    "            main_delay_sheet.update(self.msc_extractor.delay_sheet)\n",
    "        \n",
    "        if self.config.get('run_g2'):\n",
    "            main_delay_sheet.update(self.g2_extractor.delay_sheet)\n",
    "\n",
    "        # Calculate the deltas\n",
    "        main_delay_sheet['No. of days delayed ETD'] = (main_delay_sheet.updated_etd\n",
    "                                                       - pd.to_datetime(main_delay_sheet['ETD Date'])).dt.days\n",
    "        main_delay_sheet['No. of days delayed ETA'] = (main_delay_sheet.updated_eta\n",
    "                                                       - pd.to_datetime(main_delay_sheet['Disport ETA'])).dt.days\n",
    "\n",
    "        # Format the dates correctly via strftime\n",
    "        date_columns = ['ETD Date', 'Disport ETA', 'updated_etd', 'updated_eta']\n",
    "        for column in date_columns:\n",
    "            main_delay_sheet[column] = main_delay_sheet[column].dt.strftime('%d/%m/%Y')\n",
    "        self.main_delay_sheet = main_delay_sheet.copy()\n",
    "    \n",
    "    def output(self):\n",
    "        # Output the excel file\n",
    "        saved_file = f\"Vessel Delay Tracking - {date.today().strftime('%d.%m.%Y')}.xlsx\"\n",
    "        self.main_delay_sheet.to_excel(saved_file)\n",
    "        # os.startfile(saved_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delay report skeleton\n",
    "delay_report = DelayReport()\n",
    "delay_report.run_bs()\n",
    "delay_report.run_msc()\n",
    "delay_report.run_g2()\n",
    "delay_report.assemble()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
